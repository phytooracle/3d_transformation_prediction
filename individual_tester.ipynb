{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_data(group):\n",
    "    data_list = []\n",
    "    dt_list = []\n",
    "    filename_list = []\n",
    "\n",
    "    for key in group.keys():\n",
    "        \n",
    "        for key2 in group[key].keys():\n",
    "\n",
    "            dt = datetime.strptime(' '.join([key.split('__')[-2], key.split('__')[-1].replace('-', ':')]), \n",
    "                                        \"%Y-%m-%d %H:%M:%S:%f\")\n",
    "            data = np.array(group[key][key2])\n",
    "            data_list.append(data)\n",
    "            dt_list.append(dt)\n",
    "            filename_list.append(key2)\n",
    "    \n",
    "    df = pd.DataFrame({'filename': filename_list, 'data': data_list, 'dt': dt_list})\n",
    "    return df\n",
    "\n",
    "def plot_loss(history, num_epochs):\n",
    "    plt.plot(history.history['loss'][:num_epochs], label='loss')\n",
    "    plt.plot(history.history['val_loss'][:num_epochs], label='val_loss')\n",
    "    # plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [mm]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of all H5 files\n",
    "# h5_files = glob.glob('scanner3DTop_Transformations/TESTDATASET_*/*.h5')\n",
    "h5_files = glob.glob('scanner3DTop_Transformations/**/**/**.h5', recursive= True)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for h5_file in h5_files:\n",
    "\n",
    "    # Open H5 file\n",
    "    h5 = h5py.File(h5_file, 'r')\n",
    "    keys = list(h5.keys())\n",
    "    \n",
    "    if \"EW\" in keys and \"NS\" in keys and \"environment_logger\" in keys:\n",
    "\n",
    "        # Get negative direction transformations\n",
    "        negative = get_group_data(group=h5[\"EW/individual/transformations/negative/\"])\n",
    "\n",
    "        # Get positive direction transformations\n",
    "        positive = get_group_data(group=h5[\"EW/individual/transformations/positive/\"])\n",
    "\n",
    "        # Combine positive and negative transformations\n",
    "        transformations = pd.concat([positive, negative])\n",
    "\n",
    "        # Extract Environment Logger data\n",
    "        df = pd.read_hdf(h5_file, 'environment_logger') \n",
    "\n",
    "        # Merge transformations and Environment logger data\n",
    "        df = df.merge(transformations, on='filename')\n",
    "\n",
    "        # Drop unwanted columns\n",
    "        df = df.drop(['directories', 'filename', 'dt'], axis=1)\n",
    "\n",
    "        # Flatten the transformations\n",
    "        df['data'] = df['data'].apply(lambda x: x.flatten())\n",
    "\n",
    "        df['field'] = df['field'].map({'north': 0.0, 'south': 1.0})\n",
    "        df['scan_direction'] = df['scan_direction'].map({'Negative': 0.0, 'Positive': 1.0})\n",
    "        df = df.drop(['brightness'], axis=1) #, 'time'\n",
    "\n",
    "        # Reset the index of your DataFrame\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Add to list\n",
    "        df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X, Y, Z transformations\n",
    "df['data'] = df['data'].apply(lambda x: x.reshape(4, 4)[:3,3])#[:3])\n",
    "# df['data'] = df['data'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sunDirection</th>\n",
       "      <th>airPressure</th>\n",
       "      <th>relHumidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windDirection</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>windVelocity</th>\n",
       "      <th>par</th>\n",
       "      <th>field</th>\n",
       "      <th>x_position</th>\n",
       "      <th>y_position</th>\n",
       "      <th>z_position</th>\n",
       "      <th>scan_direction</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-05 23:09:24</td>\n",
       "      <td>338.213446</td>\n",
       "      <td>1010.343944</td>\n",
       "      <td>19.568468</td>\n",
       "      <td>25.102084</td>\n",
       "      <td>173.380535</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>3.887448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.8460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-15.0, -15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-05 23:11:12</td>\n",
       "      <td>338.707846</td>\n",
       "      <td>1010.407422</td>\n",
       "      <td>19.681387</td>\n",
       "      <td>25.071566</td>\n",
       "      <td>171.128269</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>3.416852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.5450</td>\n",
       "      <td>22.135</td>\n",
       "      <td>1.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-10.0, 15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-05 23:13:01</td>\n",
       "      <td>339.213233</td>\n",
       "      <td>1010.383618</td>\n",
       "      <td>19.989624</td>\n",
       "      <td>24.931181</td>\n",
       "      <td>171.402936</td>\n",
       "      <td>0.086451</td>\n",
       "      <td>3.394879</td>\n",
       "      <td>1.465023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.2460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-20.0, -15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-05 23:14:50</td>\n",
       "      <td>339.707633</td>\n",
       "      <td>1010.296335</td>\n",
       "      <td>19.870602</td>\n",
       "      <td>24.949492</td>\n",
       "      <td>162.470779</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>3.050630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.9455</td>\n",
       "      <td>22.135</td>\n",
       "      <td>1.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-15.0, 10.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-05 23:16:38</td>\n",
       "      <td>340.311899</td>\n",
       "      <td>1010.256661</td>\n",
       "      <td>19.965209</td>\n",
       "      <td>24.827418</td>\n",
       "      <td>158.658406</td>\n",
       "      <td>0.086451</td>\n",
       "      <td>3.517563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.6455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-10.0, -10.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>2023-07-21 16:27:18</td>\n",
       "      <td>272.403333</td>\n",
       "      <td>1004.527726</td>\n",
       "      <td>16.840114</td>\n",
       "      <td>44.298227</td>\n",
       "      <td>268.008667</td>\n",
       "      <td>0.110866</td>\n",
       "      <td>6.912442</td>\n",
       "      <td>1120.253937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.5460</td>\n",
       "      <td>22.135</td>\n",
       "      <td>2.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[115.0, 85.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>2023-07-21 16:29:13</td>\n",
       "      <td>272.721946</td>\n",
       "      <td>1004.511856</td>\n",
       "      <td>17.099521</td>\n",
       "      <td>44.578997</td>\n",
       "      <td>273.732719</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>4.070559</td>\n",
       "      <td>1103.162007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.2460</td>\n",
       "      <td>3.800</td>\n",
       "      <td>2.319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[120.0, 30.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>2023-07-21 16:31:07</td>\n",
       "      <td>272.919706</td>\n",
       "      <td>1004.503922</td>\n",
       "      <td>17.221595</td>\n",
       "      <td>44.548479</td>\n",
       "      <td>265.437788</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>6.286203</td>\n",
       "      <td>1090.953486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.9460</td>\n",
       "      <td>22.135</td>\n",
       "      <td>2.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[25.0, -15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>2023-07-21 16:33:00</td>\n",
       "      <td>273.216346</td>\n",
       "      <td>1004.456313</td>\n",
       "      <td>17.334513</td>\n",
       "      <td>44.426405</td>\n",
       "      <td>269.436934</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>4.409314</td>\n",
       "      <td>1073.373215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.6455</td>\n",
       "      <td>3.800</td>\n",
       "      <td>2.319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[390.0, 250.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>2023-07-21 16:34:56</td>\n",
       "      <td>273.414106</td>\n",
       "      <td>1004.392834</td>\n",
       "      <td>17.447432</td>\n",
       "      <td>44.246345</td>\n",
       "      <td>288.586688</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>4.477065</td>\n",
       "      <td>1069.466488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.3460</td>\n",
       "      <td>22.135</td>\n",
       "      <td>2.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[85.0, 50.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4229 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  sunDirection  airPressure  relHumidity  temperature  \\\n",
       "0    2022-05-05 23:09:24    338.213446  1010.343944    19.568468    25.102084   \n",
       "1    2022-05-05 23:11:12    338.707846  1010.407422    19.681387    25.071566   \n",
       "2    2022-05-05 23:13:01    339.213233  1010.383618    19.989624    24.931181   \n",
       "3    2022-05-05 23:14:50    339.707633  1010.296335    19.870602    24.949492   \n",
       "4    2022-05-05 23:16:38    340.311899  1010.256661    19.965209    24.827418   \n",
       "...                  ...           ...          ...          ...          ...   \n",
       "4224 2023-07-21 16:27:18    272.403333  1004.527726    16.840114    44.298227   \n",
       "4225 2023-07-21 16:29:13    272.721946  1004.511856    17.099521    44.578997   \n",
       "4226 2023-07-21 16:31:07    272.919706  1004.503922    17.221595    44.548479   \n",
       "4227 2023-07-21 16:33:00    273.216346  1004.456313    17.334513    44.426405   \n",
       "4228 2023-07-21 16:34:56    273.414106  1004.392834    17.447432    44.246345   \n",
       "\n",
       "      windDirection  precipitation  windVelocity          par  field  \\\n",
       "0        173.380535       0.089503      3.887448     0.000000    0.0   \n",
       "1        171.128269       0.089503      3.416852     0.000000    0.0   \n",
       "2        171.402936       0.086451      3.394879     1.465023    0.0   \n",
       "3        162.470779       0.089503      3.050630     0.000000    0.0   \n",
       "4        158.658406       0.086451      3.517563     0.000000    0.0   \n",
       "...             ...            ...           ...          ...    ...   \n",
       "4224     268.008667       0.110866      6.912442  1120.253937    0.0   \n",
       "4225     273.732719       0.104762      4.070559  1103.162007    0.0   \n",
       "4226     265.437788       0.104762      6.286203  1090.953486    0.0   \n",
       "4227     269.436934       0.104762      4.409314  1073.373215    0.0   \n",
       "4228     288.586688       0.104762      4.477065  1069.466488    0.0   \n",
       "\n",
       "      x_position  y_position  z_position  scan_direction                 data  \n",
       "0       303.8460       0.000       1.234             1.0  [-15.0, -15.0, 0.0]  \n",
       "1       304.5450      22.135       1.234             0.0   [-10.0, 15.0, 0.0]  \n",
       "2       305.2460       0.000       1.234             1.0  [-20.0, -15.0, 0.0]  \n",
       "3       305.9455      22.135       1.234             0.0   [-15.0, 10.0, 0.0]  \n",
       "4       306.6455       0.000       1.234             1.0  [-10.0, -10.0, 0.0]  \n",
       "...          ...         ...         ...             ...                  ...  \n",
       "4224    304.5460      22.135       2.319             0.0   [115.0, 85.0, 0.0]  \n",
       "4225    305.2460       3.800       2.319             1.0   [120.0, 30.0, 0.0]  \n",
       "4226    305.9460      22.135       2.319             0.0   [25.0, -15.0, 0.0]  \n",
       "4227    306.6455       3.800       2.319             1.0  [390.0, 250.0, 0.0]  \n",
       "4228    307.3460      22.135       2.319             0.0    [85.0, 50.0, 0.0]  \n",
       "\n",
       "[4229 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sunDirection</th>\n",
       "      <th>airPressure</th>\n",
       "      <th>relHumidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windDirection</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>windVelocity</th>\n",
       "      <th>x_position</th>\n",
       "      <th>y_position</th>\n",
       "      <th>z_position</th>\n",
       "      <th>scan_direction</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>273.414106</td>\n",
       "      <td>1004.392834</td>\n",
       "      <td>17.447432</td>\n",
       "      <td>44.246345</td>\n",
       "      <td>288.586688</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>4.477065</td>\n",
       "      <td>307.346</td>\n",
       "      <td>22.135</td>\n",
       "      <td>2.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[85.0, 50.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sunDirection  airPressure  relHumidity  temperature  windDirection  \\\n",
       "4228    273.414106  1004.392834    17.447432    44.246345     288.586688   \n",
       "\n",
       "      precipitation  windVelocity  x_position  y_position  z_position  \\\n",
       "4228       0.104762      4.477065     307.346      22.135       2.319   \n",
       "\n",
       "      scan_direction               data  \n",
       "4228             0.0  [85.0, 50.0, 0.0]  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ply_metadata = df.iloc[[4228]]\n",
    "test_ply_metadata=test_ply_metadata.drop([\"time\", \"par\", \"field\"], axis=1)\n",
    "test_ply_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sunDirection</th>\n",
       "      <th>airPressure</th>\n",
       "      <th>relHumidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windDirection</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>windVelocity</th>\n",
       "      <th>x_position</th>\n",
       "      <th>y_position</th>\n",
       "      <th>z_position</th>\n",
       "      <th>scan_direction</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338.213446</td>\n",
       "      <td>1010.343944</td>\n",
       "      <td>19.568468</td>\n",
       "      <td>25.102084</td>\n",
       "      <td>173.380535</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>3.887448</td>\n",
       "      <td>303.8460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-15.0, -15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338.707846</td>\n",
       "      <td>1010.407422</td>\n",
       "      <td>19.681387</td>\n",
       "      <td>25.071566</td>\n",
       "      <td>171.128269</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>3.416852</td>\n",
       "      <td>304.5450</td>\n",
       "      <td>22.135</td>\n",
       "      <td>1.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-10.0, 15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339.213233</td>\n",
       "      <td>1010.383618</td>\n",
       "      <td>19.989624</td>\n",
       "      <td>24.931181</td>\n",
       "      <td>171.402936</td>\n",
       "      <td>0.086451</td>\n",
       "      <td>3.394879</td>\n",
       "      <td>305.2460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-20.0, -15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>339.707633</td>\n",
       "      <td>1010.296335</td>\n",
       "      <td>19.870602</td>\n",
       "      <td>24.949492</td>\n",
       "      <td>162.470779</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>3.050630</td>\n",
       "      <td>305.9455</td>\n",
       "      <td>22.135</td>\n",
       "      <td>1.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-15.0, 10.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>340.311899</td>\n",
       "      <td>1010.256661</td>\n",
       "      <td>19.965209</td>\n",
       "      <td>24.827418</td>\n",
       "      <td>158.658406</td>\n",
       "      <td>0.086451</td>\n",
       "      <td>3.517563</td>\n",
       "      <td>306.6455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-10.0, -10.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>272.403333</td>\n",
       "      <td>1004.527726</td>\n",
       "      <td>16.840114</td>\n",
       "      <td>44.298227</td>\n",
       "      <td>268.008667</td>\n",
       "      <td>0.110866</td>\n",
       "      <td>6.912442</td>\n",
       "      <td>304.5460</td>\n",
       "      <td>22.135</td>\n",
       "      <td>2.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[115.0, 85.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>272.721946</td>\n",
       "      <td>1004.511856</td>\n",
       "      <td>17.099521</td>\n",
       "      <td>44.578997</td>\n",
       "      <td>273.732719</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>4.070559</td>\n",
       "      <td>305.2460</td>\n",
       "      <td>3.800</td>\n",
       "      <td>2.319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[120.0, 30.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>272.919706</td>\n",
       "      <td>1004.503922</td>\n",
       "      <td>17.221595</td>\n",
       "      <td>44.548479</td>\n",
       "      <td>265.437788</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>6.286203</td>\n",
       "      <td>305.9460</td>\n",
       "      <td>22.135</td>\n",
       "      <td>2.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[25.0, -15.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>273.216346</td>\n",
       "      <td>1004.456313</td>\n",
       "      <td>17.334513</td>\n",
       "      <td>44.426405</td>\n",
       "      <td>269.436934</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>4.409314</td>\n",
       "      <td>306.6455</td>\n",
       "      <td>3.800</td>\n",
       "      <td>2.319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[390.0, 250.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>273.414106</td>\n",
       "      <td>1004.392834</td>\n",
       "      <td>17.447432</td>\n",
       "      <td>44.246345</td>\n",
       "      <td>288.586688</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>4.477065</td>\n",
       "      <td>307.3460</td>\n",
       "      <td>22.135</td>\n",
       "      <td>2.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[85.0, 50.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4229 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sunDirection  airPressure  relHumidity  temperature  windDirection  \\\n",
       "0       338.213446  1010.343944    19.568468    25.102084     173.380535   \n",
       "1       338.707846  1010.407422    19.681387    25.071566     171.128269   \n",
       "2       339.213233  1010.383618    19.989624    24.931181     171.402936   \n",
       "3       339.707633  1010.296335    19.870602    24.949492     162.470779   \n",
       "4       340.311899  1010.256661    19.965209    24.827418     158.658406   \n",
       "...            ...          ...          ...          ...            ...   \n",
       "4224    272.403333  1004.527726    16.840114    44.298227     268.008667   \n",
       "4225    272.721946  1004.511856    17.099521    44.578997     273.732719   \n",
       "4226    272.919706  1004.503922    17.221595    44.548479     265.437788   \n",
       "4227    273.216346  1004.456313    17.334513    44.426405     269.436934   \n",
       "4228    273.414106  1004.392834    17.447432    44.246345     288.586688   \n",
       "\n",
       "      precipitation  windVelocity  x_position  y_position  z_position  \\\n",
       "0          0.089503      3.887448    303.8460       0.000       1.234   \n",
       "1          0.089503      3.416852    304.5450      22.135       1.234   \n",
       "2          0.086451      3.394879    305.2460       0.000       1.234   \n",
       "3          0.089503      3.050630    305.9455      22.135       1.234   \n",
       "4          0.086451      3.517563    306.6455       0.000       1.234   \n",
       "...             ...           ...         ...         ...         ...   \n",
       "4224       0.110866      6.912442    304.5460      22.135       2.319   \n",
       "4225       0.104762      4.070559    305.2460       3.800       2.319   \n",
       "4226       0.104762      6.286203    305.9460      22.135       2.319   \n",
       "4227       0.104762      4.409314    306.6455       3.800       2.319   \n",
       "4228       0.104762      4.477065    307.3460      22.135       2.319   \n",
       "\n",
       "      scan_direction                 data  \n",
       "0                1.0  [-15.0, -15.0, 0.0]  \n",
       "1                0.0   [-10.0, 15.0, 0.0]  \n",
       "2                1.0  [-20.0, -15.0, 0.0]  \n",
       "3                0.0   [-15.0, 10.0, 0.0]  \n",
       "4                1.0  [-10.0, -10.0, 0.0]  \n",
       "...              ...                  ...  \n",
       "4224             0.0   [115.0, 85.0, 0.0]  \n",
       "4225             1.0   [120.0, 30.0, 0.0]  \n",
       "4226             0.0   [25.0, -15.0, 0.0]  \n",
       "4227             1.0  [390.0, 250.0, 0.0]  \n",
       "4228             0.0    [85.0, 50.0, 0.0]  \n",
       "\n",
       "[4229 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= df.drop(['time', 'par','field'], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df2\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "# Convert any Timestamps in the input features to a numerical representation\n",
    "# dataset = dataset.apply(lambda x: x.astype(int) if np.issubdtype(x.dtype, np.datetime64) else x)\n",
    "#dataset['time'] = dataset['time'].values.astype(int)\n",
    "\n",
    "# Convert only the columns with numeric data types to float\n",
    "#dataset[dataset.select_dtypes(include='number').columns] = dataset.select_dtypes(include='number').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('data')\n",
    "test_labels = test_features.pop('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.tolist()\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_labels = test_labels.tolist()\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3383, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train_features = scaler.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dl1 (Dense)                 (None, 112)               1344      \n",
      "                                                                 \n",
      " dl2 (Dense)                 (None, 112)               12656     \n",
      "                                                                 \n",
      " dl3 (Dense)                 (None, 112)               12656     \n",
      "                                                                 \n",
      " reshape_layer (Reshape)     (None, 1, 112)            0         \n",
      "                                                                 \n",
      " rnn2_layer (SimpleRNN)      (None, 112)               25200     \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 3)                 339       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,195\n",
      "Trainable params: 52,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/998\n",
      "85/85 [==============================] - 3s 8ms/step - loss: 30.6319 - accuracy: 0.6053 - val_loss: 36.1420 - val_accuracy: 0.6839\n",
      "Epoch 2/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 29.7637 - accuracy: 0.6600 - val_loss: 35.5028 - val_accuracy: 0.6824\n",
      "Epoch 3/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 29.1288 - accuracy: 0.6785 - val_loss: 34.8154 - val_accuracy: 0.6883\n",
      "Epoch 4/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 28.5792 - accuracy: 0.6715 - val_loss: 34.0236 - val_accuracy: 0.7371\n",
      "Epoch 5/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 28.0534 - accuracy: 0.6977 - val_loss: 33.5366 - val_accuracy: 0.7105\n",
      "Epoch 6/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 27.5385 - accuracy: 0.7010 - val_loss: 32.9912 - val_accuracy: 0.7356\n",
      "Epoch 7/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 26.9968 - accuracy: 0.7092 - val_loss: 32.5682 - val_accuracy: 0.7031\n",
      "Epoch 8/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 26.7686 - accuracy: 0.6988 - val_loss: 32.7337 - val_accuracy: 0.7282\n",
      "Epoch 9/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 26.3404 - accuracy: 0.7007 - val_loss: 32.3752 - val_accuracy: 0.7090\n",
      "Epoch 10/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 26.0257 - accuracy: 0.6966 - val_loss: 32.1679 - val_accuracy: 0.7297\n",
      "Epoch 11/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 25.7592 - accuracy: 0.6992 - val_loss: 31.6269 - val_accuracy: 0.7208\n",
      "Epoch 12/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 25.4977 - accuracy: 0.6999 - val_loss: 32.0598 - val_accuracy: 0.6883\n",
      "Epoch 13/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 25.2018 - accuracy: 0.7007 - val_loss: 31.3600 - val_accuracy: 0.7253\n",
      "Epoch 14/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 25.0052 - accuracy: 0.7073 - val_loss: 30.7845 - val_accuracy: 0.7282\n",
      "Epoch 15/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 24.7523 - accuracy: 0.7036 - val_loss: 30.9146 - val_accuracy: 0.7282\n",
      "Epoch 16/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 24.6237 - accuracy: 0.7033 - val_loss: 30.4920 - val_accuracy: 0.7312\n",
      "Epoch 17/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 24.3865 - accuracy: 0.7077 - val_loss: 30.8497 - val_accuracy: 0.7194\n",
      "Epoch 18/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 24.1799 - accuracy: 0.7077 - val_loss: 30.0145 - val_accuracy: 0.7297\n",
      "Epoch 19/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 23.9681 - accuracy: 0.7095 - val_loss: 30.0965 - val_accuracy: 0.7415\n",
      "Epoch 20/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 23.5782 - accuracy: 0.7140 - val_loss: 30.1310 - val_accuracy: 0.7415\n",
      "Epoch 21/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 23.5048 - accuracy: 0.7236 - val_loss: 30.0837 - val_accuracy: 0.7356\n",
      "Epoch 22/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 23.2621 - accuracy: 0.7236 - val_loss: 29.9486 - val_accuracy: 0.7400\n",
      "Epoch 23/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 23.0086 - accuracy: 0.7214 - val_loss: 29.6927 - val_accuracy: 0.7400\n",
      "Epoch 24/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 22.8678 - accuracy: 0.7299 - val_loss: 29.5067 - val_accuracy: 0.7533\n",
      "Epoch 25/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 22.6457 - accuracy: 0.7387 - val_loss: 29.4007 - val_accuracy: 0.7578\n",
      "Epoch 26/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 22.5488 - accuracy: 0.7373 - val_loss: 29.4568 - val_accuracy: 0.7489\n",
      "Epoch 27/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 22.3781 - accuracy: 0.7295 - val_loss: 29.1785 - val_accuracy: 0.7504\n",
      "Epoch 28/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 22.2258 - accuracy: 0.7288 - val_loss: 29.0505 - val_accuracy: 0.7563\n",
      "Epoch 29/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 22.0676 - accuracy: 0.7350 - val_loss: 29.5182 - val_accuracy: 0.7371\n",
      "Epoch 30/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 21.9321 - accuracy: 0.7361 - val_loss: 29.1853 - val_accuracy: 0.7578\n",
      "Epoch 31/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 21.8268 - accuracy: 0.7365 - val_loss: 28.5490 - val_accuracy: 0.7504\n",
      "Epoch 32/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 21.6095 - accuracy: 0.7376 - val_loss: 28.6505 - val_accuracy: 0.7578\n",
      "Epoch 33/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 21.4448 - accuracy: 0.7424 - val_loss: 28.3408 - val_accuracy: 0.7548\n",
      "Epoch 34/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 21.2224 - accuracy: 0.7398 - val_loss: 28.6119 - val_accuracy: 0.7696\n",
      "Epoch 35/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 21.1038 - accuracy: 0.7465 - val_loss: 28.2787 - val_accuracy: 0.7622\n",
      "Epoch 36/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 20.8693 - accuracy: 0.7417 - val_loss: 27.9747 - val_accuracy: 0.7710\n",
      "Epoch 37/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 20.8749 - accuracy: 0.7432 - val_loss: 27.7126 - val_accuracy: 0.7681\n",
      "Epoch 38/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 20.5616 - accuracy: 0.7483 - val_loss: 27.6133 - val_accuracy: 0.7770\n",
      "Epoch 39/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 20.3790 - accuracy: 0.7506 - val_loss: 27.3296 - val_accuracy: 0.7592\n",
      "Epoch 40/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 20.3376 - accuracy: 0.7472 - val_loss: 27.2275 - val_accuracy: 0.7740\n",
      "Epoch 41/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 20.2091 - accuracy: 0.7520 - val_loss: 27.2628 - val_accuracy: 0.7637\n",
      "Epoch 42/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 19.8799 - accuracy: 0.7520 - val_loss: 27.2963 - val_accuracy: 0.7637\n",
      "Epoch 43/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 19.9012 - accuracy: 0.7546 - val_loss: 27.4076 - val_accuracy: 0.7578\n",
      "Epoch 44/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 19.8183 - accuracy: 0.7524 - val_loss: 26.8525 - val_accuracy: 0.7578\n",
      "Epoch 45/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 19.7015 - accuracy: 0.7598 - val_loss: 27.0039 - val_accuracy: 0.7637\n",
      "Epoch 46/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 19.4193 - accuracy: 0.7557 - val_loss: 26.6413 - val_accuracy: 0.7651\n",
      "Epoch 47/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 19.3003 - accuracy: 0.7550 - val_loss: 26.3109 - val_accuracy: 0.7607\n",
      "Epoch 48/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 19.1180 - accuracy: 0.7587 - val_loss: 26.6576 - val_accuracy: 0.7592\n",
      "Epoch 49/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 19.0276 - accuracy: 0.7598 - val_loss: 25.9391 - val_accuracy: 0.7710\n",
      "Epoch 50/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 18.9542 - accuracy: 0.7624 - val_loss: 26.0384 - val_accuracy: 0.7666\n",
      "Epoch 51/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 18.7242 - accuracy: 0.7653 - val_loss: 25.8766 - val_accuracy: 0.7651\n",
      "Epoch 52/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 18.5377 - accuracy: 0.7672 - val_loss: 25.5934 - val_accuracy: 0.7740\n",
      "Epoch 53/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 18.4814 - accuracy: 0.7653 - val_loss: 25.7900 - val_accuracy: 0.7592\n",
      "Epoch 54/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 18.3185 - accuracy: 0.7609 - val_loss: 25.7546 - val_accuracy: 0.7725\n",
      "Epoch 55/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 18.0649 - accuracy: 0.7687 - val_loss: 25.5126 - val_accuracy: 0.7696\n",
      "Epoch 56/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 17.9898 - accuracy: 0.7716 - val_loss: 25.0998 - val_accuracy: 0.7696\n",
      "Epoch 57/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 17.7872 - accuracy: 0.7653 - val_loss: 24.9303 - val_accuracy: 0.7651\n",
      "Epoch 58/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 17.8081 - accuracy: 0.7664 - val_loss: 24.7786 - val_accuracy: 0.7814\n",
      "Epoch 59/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 17.4740 - accuracy: 0.7683 - val_loss: 25.0677 - val_accuracy: 0.7666\n",
      "Epoch 60/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 17.7063 - accuracy: 0.7679 - val_loss: 24.5147 - val_accuracy: 0.7770\n",
      "Epoch 61/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 17.2803 - accuracy: 0.7709 - val_loss: 24.3674 - val_accuracy: 0.7755\n",
      "Epoch 62/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 17.0446 - accuracy: 0.7783 - val_loss: 24.0775 - val_accuracy: 0.7829\n",
      "Epoch 63/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 16.9410 - accuracy: 0.7764 - val_loss: 24.5047 - val_accuracy: 0.7799\n",
      "Epoch 64/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 16.9083 - accuracy: 0.7727 - val_loss: 24.0462 - val_accuracy: 0.7666\n",
      "Epoch 65/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 16.8488 - accuracy: 0.7761 - val_loss: 24.3125 - val_accuracy: 0.7740\n",
      "Epoch 66/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 16.6824 - accuracy: 0.7746 - val_loss: 23.5305 - val_accuracy: 0.7755\n",
      "Epoch 67/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 16.4392 - accuracy: 0.7779 - val_loss: 23.7263 - val_accuracy: 0.7725\n",
      "Epoch 68/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 16.2510 - accuracy: 0.7823 - val_loss: 24.0222 - val_accuracy: 0.7681\n",
      "Epoch 69/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 16.0811 - accuracy: 0.7827 - val_loss: 23.7006 - val_accuracy: 0.7725\n",
      "Epoch 70/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 16.0353 - accuracy: 0.7871 - val_loss: 23.5444 - val_accuracy: 0.7873\n",
      "Epoch 71/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 15.9610 - accuracy: 0.7897 - val_loss: 22.9301 - val_accuracy: 0.7903\n",
      "Epoch 72/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 15.8829 - accuracy: 0.7846 - val_loss: 23.0349 - val_accuracy: 0.7843\n",
      "Epoch 73/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 15.7720 - accuracy: 0.7827 - val_loss: 24.0771 - val_accuracy: 0.7843\n",
      "Epoch 74/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 15.8017 - accuracy: 0.7875 - val_loss: 22.8160 - val_accuracy: 0.7991\n",
      "Epoch 75/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 15.6264 - accuracy: 0.7834 - val_loss: 22.4929 - val_accuracy: 0.7888\n",
      "Epoch 76/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 15.2974 - accuracy: 0.7849 - val_loss: 23.7242 - val_accuracy: 0.7814\n",
      "Epoch 77/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 15.1871 - accuracy: 0.7986 - val_loss: 22.5688 - val_accuracy: 0.7858\n",
      "Epoch 78/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 14.9836 - accuracy: 0.7908 - val_loss: 22.5471 - val_accuracy: 0.7947\n",
      "Epoch 79/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 14.9345 - accuracy: 0.7897 - val_loss: 22.6671 - val_accuracy: 0.7962\n",
      "Epoch 80/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 15.0717 - accuracy: 0.7849 - val_loss: 22.7821 - val_accuracy: 0.7932\n",
      "Epoch 81/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 14.8246 - accuracy: 0.7846 - val_loss: 21.8589 - val_accuracy: 0.8065\n",
      "Epoch 82/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 14.5995 - accuracy: 0.7927 - val_loss: 22.6505 - val_accuracy: 0.7962\n",
      "Epoch 83/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 14.5676 - accuracy: 0.7938 - val_loss: 22.0968 - val_accuracy: 0.7932\n",
      "Epoch 84/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 14.5815 - accuracy: 0.7927 - val_loss: 22.1825 - val_accuracy: 0.8021\n",
      "Epoch 85/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 14.2895 - accuracy: 0.7986 - val_loss: 22.2746 - val_accuracy: 0.7991\n",
      "Epoch 86/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 14.0422 - accuracy: 0.7916 - val_loss: 21.8382 - val_accuracy: 0.7932\n",
      "Epoch 87/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 14.1488 - accuracy: 0.7990 - val_loss: 21.7521 - val_accuracy: 0.7947\n",
      "Epoch 88/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 14.1579 - accuracy: 0.7986 - val_loss: 21.1641 - val_accuracy: 0.7991\n",
      "Epoch 89/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 13.8313 - accuracy: 0.7934 - val_loss: 21.8276 - val_accuracy: 0.8006\n",
      "Epoch 90/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.6362 - accuracy: 0.8023 - val_loss: 21.0477 - val_accuracy: 0.8035\n",
      "Epoch 91/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.6946 - accuracy: 0.8027 - val_loss: 21.5118 - val_accuracy: 0.7991\n",
      "Epoch 92/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.5210 - accuracy: 0.7964 - val_loss: 21.7021 - val_accuracy: 0.7991\n",
      "Epoch 93/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.4597 - accuracy: 0.8052 - val_loss: 21.4258 - val_accuracy: 0.8021\n",
      "Epoch 94/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 13.4478 - accuracy: 0.8049 - val_loss: 21.4070 - val_accuracy: 0.7947\n",
      "Epoch 95/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 13.4239 - accuracy: 0.8004 - val_loss: 20.6071 - val_accuracy: 0.8080\n",
      "Epoch 96/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.2835 - accuracy: 0.8071 - val_loss: 20.9535 - val_accuracy: 0.7991\n",
      "Epoch 97/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.0542 - accuracy: 0.8041 - val_loss: 21.0911 - val_accuracy: 0.8198\n",
      "Epoch 98/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 13.1175 - accuracy: 0.8049 - val_loss: 21.6608 - val_accuracy: 0.8006\n",
      "Epoch 99/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.1070 - accuracy: 0.8078 - val_loss: 20.7843 - val_accuracy: 0.7991\n",
      "Epoch 100/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.8977 - accuracy: 0.8101 - val_loss: 20.4795 - val_accuracy: 0.8050\n",
      "Epoch 101/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 13.0004 - accuracy: 0.8064 - val_loss: 20.0999 - val_accuracy: 0.8095\n",
      "Epoch 102/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.8673 - accuracy: 0.8045 - val_loss: 20.0261 - val_accuracy: 0.8080\n",
      "Epoch 103/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.7865 - accuracy: 0.8112 - val_loss: 20.4072 - val_accuracy: 0.8021\n",
      "Epoch 104/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.5813 - accuracy: 0.8123 - val_loss: 20.4549 - val_accuracy: 0.7991\n",
      "Epoch 105/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.6094 - accuracy: 0.8167 - val_loss: 20.0225 - val_accuracy: 0.8124\n",
      "Epoch 106/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 12.2329 - accuracy: 0.8104 - val_loss: 20.3034 - val_accuracy: 0.8080\n",
      "Epoch 107/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.2626 - accuracy: 0.8119 - val_loss: 20.3164 - val_accuracy: 0.7947\n",
      "Epoch 108/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.3604 - accuracy: 0.8108 - val_loss: 20.1118 - val_accuracy: 0.8006\n",
      "Epoch 109/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.4155 - accuracy: 0.8149 - val_loss: 19.8810 - val_accuracy: 0.8095\n",
      "Epoch 110/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 12.3592 - accuracy: 0.8126 - val_loss: 20.2829 - val_accuracy: 0.7903\n",
      "Epoch 111/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.0785 - accuracy: 0.8108 - val_loss: 20.1509 - val_accuracy: 0.8109\n",
      "Epoch 112/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.1043 - accuracy: 0.8130 - val_loss: 20.1050 - val_accuracy: 0.7962\n",
      "Epoch 113/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.9951 - accuracy: 0.8178 - val_loss: 19.9333 - val_accuracy: 0.7917\n",
      "Epoch 114/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.8575 - accuracy: 0.8186 - val_loss: 19.4577 - val_accuracy: 0.7976\n",
      "Epoch 115/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.7925 - accuracy: 0.8137 - val_loss: 19.3293 - val_accuracy: 0.8080\n",
      "Epoch 116/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.7902 - accuracy: 0.8167 - val_loss: 19.6488 - val_accuracy: 0.8035\n",
      "Epoch 117/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.8662 - accuracy: 0.8182 - val_loss: 19.3722 - val_accuracy: 0.7991\n",
      "Epoch 118/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 11.8793 - accuracy: 0.8137 - val_loss: 19.6843 - val_accuracy: 0.8035\n",
      "Epoch 119/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.5251 - accuracy: 0.8160 - val_loss: 19.4966 - val_accuracy: 0.8080\n",
      "Epoch 120/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.5005 - accuracy: 0.8178 - val_loss: 19.6186 - val_accuracy: 0.8065\n",
      "Epoch 121/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.5874 - accuracy: 0.8208 - val_loss: 19.3450 - val_accuracy: 0.7976\n",
      "Epoch 122/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.5415 - accuracy: 0.8189 - val_loss: 19.2823 - val_accuracy: 0.7976\n",
      "Epoch 123/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.4394 - accuracy: 0.8234 - val_loss: 18.9441 - val_accuracy: 0.8080\n",
      "Epoch 124/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.2624 - accuracy: 0.8193 - val_loss: 19.4473 - val_accuracy: 0.7917\n",
      "Epoch 125/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.2892 - accuracy: 0.8104 - val_loss: 18.9085 - val_accuracy: 0.8050\n",
      "Epoch 126/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.0784 - accuracy: 0.8252 - val_loss: 18.8389 - val_accuracy: 0.7858\n",
      "Epoch 127/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.0370 - accuracy: 0.8182 - val_loss: 19.1546 - val_accuracy: 0.7976\n",
      "Epoch 128/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 11.1341 - accuracy: 0.8152 - val_loss: 18.8956 - val_accuracy: 0.8006\n",
      "Epoch 129/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.9163 - accuracy: 0.8189 - val_loss: 19.0141 - val_accuracy: 0.8035\n",
      "Epoch 130/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.8947 - accuracy: 0.8197 - val_loss: 18.8679 - val_accuracy: 0.8065\n",
      "Epoch 131/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.7655 - accuracy: 0.8259 - val_loss: 18.1674 - val_accuracy: 0.7962\n",
      "Epoch 132/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 10.6233 - accuracy: 0.8219 - val_loss: 17.7892 - val_accuracy: 0.8021\n",
      "Epoch 133/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 10.5404 - accuracy: 0.8267 - val_loss: 18.0523 - val_accuracy: 0.7962\n",
      "Epoch 134/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.6340 - accuracy: 0.8215 - val_loss: 18.5201 - val_accuracy: 0.7932\n",
      "Epoch 135/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.5079 - accuracy: 0.8230 - val_loss: 18.0382 - val_accuracy: 0.8050\n",
      "Epoch 136/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.5420 - accuracy: 0.8237 - val_loss: 18.5373 - val_accuracy: 0.8065\n",
      "Epoch 137/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.3396 - accuracy: 0.8204 - val_loss: 17.9445 - val_accuracy: 0.8006\n",
      "Epoch 138/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.3150 - accuracy: 0.8230 - val_loss: 17.7994 - val_accuracy: 0.8021\n",
      "Epoch 139/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.4941 - accuracy: 0.8237 - val_loss: 17.8171 - val_accuracy: 0.8035\n",
      "Epoch 140/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.2096 - accuracy: 0.8215 - val_loss: 17.7211 - val_accuracy: 0.8065\n",
      "Epoch 141/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.1640 - accuracy: 0.8252 - val_loss: 17.7436 - val_accuracy: 0.8213\n",
      "Epoch 142/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.2402 - accuracy: 0.8237 - val_loss: 17.1358 - val_accuracy: 0.7991\n",
      "Epoch 143/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.0730 - accuracy: 0.8230 - val_loss: 17.6467 - val_accuracy: 0.8109\n",
      "Epoch 144/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.1874 - accuracy: 0.8289 - val_loss: 18.0636 - val_accuracy: 0.8006\n",
      "Epoch 145/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 9.9520 - accuracy: 0.8230 - val_loss: 17.3825 - val_accuracy: 0.8065\n",
      "Epoch 146/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.8699 - accuracy: 0.8200 - val_loss: 17.1401 - val_accuracy: 0.8065\n",
      "Epoch 147/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 9.7351 - accuracy: 0.8256 - val_loss: 17.2463 - val_accuracy: 0.8095\n",
      "Epoch 148/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 10.0468 - accuracy: 0.8211 - val_loss: 17.2614 - val_accuracy: 0.8065\n",
      "Epoch 149/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.7947 - accuracy: 0.8267 - val_loss: 17.5789 - val_accuracy: 0.8139\n",
      "Epoch 150/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.9134 - accuracy: 0.8222 - val_loss: 17.7411 - val_accuracy: 0.8035\n",
      "Epoch 151/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.8477 - accuracy: 0.8252 - val_loss: 17.1532 - val_accuracy: 0.8139\n",
      "Epoch 152/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.5732 - accuracy: 0.8285 - val_loss: 17.3094 - val_accuracy: 0.8035\n",
      "Epoch 153/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.7767 - accuracy: 0.8259 - val_loss: 17.6725 - val_accuracy: 0.8065\n",
      "Epoch 154/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.4244 - accuracy: 0.8304 - val_loss: 17.0724 - val_accuracy: 0.7947\n",
      "Epoch 155/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.5202 - accuracy: 0.8344 - val_loss: 17.4017 - val_accuracy: 0.7991\n",
      "Epoch 156/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.6727 - accuracy: 0.8271 - val_loss: 17.3782 - val_accuracy: 0.7976\n",
      "Epoch 157/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.4457 - accuracy: 0.8267 - val_loss: 16.8132 - val_accuracy: 0.8198\n",
      "Epoch 158/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 9.2934 - accuracy: 0.8300 - val_loss: 16.7858 - val_accuracy: 0.8109\n",
      "Epoch 159/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 9.2726 - accuracy: 0.8337 - val_loss: 17.2193 - val_accuracy: 0.8050\n",
      "Epoch 160/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 9.3421 - accuracy: 0.8344 - val_loss: 17.2449 - val_accuracy: 0.8035\n",
      "Epoch 161/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 9.3699 - accuracy: 0.8311 - val_loss: 16.9061 - val_accuracy: 0.8095\n",
      "Epoch 162/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 9.3438 - accuracy: 0.8271 - val_loss: 16.2321 - val_accuracy: 0.8095\n",
      "Epoch 163/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 9.2767 - accuracy: 0.8333 - val_loss: 16.5732 - val_accuracy: 0.7991\n",
      "Epoch 164/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 9.2608 - accuracy: 0.8259 - val_loss: 16.4325 - val_accuracy: 0.8095\n",
      "Epoch 165/998\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 9.1138 - accuracy: 0.8348 - val_loss: 16.5151 - val_accuracy: 0.8095\n",
      "Epoch 166/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 9.2498 - accuracy: 0.8322 - val_loss: 16.0676 - val_accuracy: 0.8198\n",
      "Epoch 167/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 8.9920 - accuracy: 0.8363 - val_loss: 16.9292 - val_accuracy: 0.8095\n",
      "Epoch 168/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 8.8048 - accuracy: 0.8356 - val_loss: 16.6090 - val_accuracy: 0.8227\n",
      "Epoch 169/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 9.2798 - accuracy: 0.8374 - val_loss: 16.3612 - val_accuracy: 0.8154\n",
      "Epoch 170/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 9.0068 - accuracy: 0.8293 - val_loss: 16.7344 - val_accuracy: 0.8065\n",
      "Epoch 171/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 8.8067 - accuracy: 0.8348 - val_loss: 16.6888 - val_accuracy: 0.8242\n",
      "Epoch 172/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 8.9221 - accuracy: 0.8311 - val_loss: 16.8310 - val_accuracy: 0.8168\n",
      "Epoch 173/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 8.7913 - accuracy: 0.8337 - val_loss: 15.8330 - val_accuracy: 0.8139\n",
      "Epoch 174/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 8.7000 - accuracy: 0.8415 - val_loss: 15.6579 - val_accuracy: 0.8124\n",
      "Epoch 175/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 8.6689 - accuracy: 0.8344 - val_loss: 16.0362 - val_accuracy: 0.8154\n",
      "Epoch 176/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 8.6365 - accuracy: 0.8400 - val_loss: 15.9404 - val_accuracy: 0.8272\n",
      "Epoch 177/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.5824 - accuracy: 0.8359 - val_loss: 15.9972 - val_accuracy: 0.8198\n",
      "Epoch 178/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.5809 - accuracy: 0.8370 - val_loss: 16.4794 - val_accuracy: 0.8080\n",
      "Epoch 179/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.6037 - accuracy: 0.8319 - val_loss: 15.6677 - val_accuracy: 0.8213\n",
      "Epoch 180/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.4179 - accuracy: 0.8418 - val_loss: 15.4405 - val_accuracy: 0.8227\n",
      "Epoch 181/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.8156 - accuracy: 0.8333 - val_loss: 16.0165 - val_accuracy: 0.8257\n",
      "Epoch 182/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.4911 - accuracy: 0.8322 - val_loss: 16.1021 - val_accuracy: 0.8139\n",
      "Epoch 183/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.5343 - accuracy: 0.8374 - val_loss: 15.9011 - val_accuracy: 0.8109\n",
      "Epoch 184/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.6137 - accuracy: 0.8404 - val_loss: 15.4667 - val_accuracy: 0.8168\n",
      "Epoch 185/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.3884 - accuracy: 0.8378 - val_loss: 16.0696 - val_accuracy: 0.8198\n",
      "Epoch 186/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.3384 - accuracy: 0.8396 - val_loss: 15.5812 - val_accuracy: 0.8154\n",
      "Epoch 187/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.1466 - accuracy: 0.8344 - val_loss: 15.2851 - val_accuracy: 0.8331\n",
      "Epoch 188/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.2112 - accuracy: 0.8385 - val_loss: 15.9179 - val_accuracy: 0.8154\n",
      "Epoch 189/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.1318 - accuracy: 0.8415 - val_loss: 15.5811 - val_accuracy: 0.8080\n",
      "Epoch 190/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.1060 - accuracy: 0.8422 - val_loss: 14.9335 - val_accuracy: 0.8272\n",
      "Epoch 191/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.2048 - accuracy: 0.8363 - val_loss: 15.1713 - val_accuracy: 0.8183\n",
      "Epoch 192/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.1926 - accuracy: 0.8392 - val_loss: 15.6616 - val_accuracy: 0.8154\n",
      "Epoch 193/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.0160 - accuracy: 0.8415 - val_loss: 15.4676 - val_accuracy: 0.8272\n",
      "Epoch 194/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 8.0942 - accuracy: 0.8485 - val_loss: 15.1945 - val_accuracy: 0.8213\n",
      "Epoch 195/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.8977 - accuracy: 0.8411 - val_loss: 15.0986 - val_accuracy: 0.8198\n",
      "Epoch 196/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.9386 - accuracy: 0.8426 - val_loss: 14.7385 - val_accuracy: 0.8183\n",
      "Epoch 197/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 7.9944 - accuracy: 0.8444 - val_loss: 14.8708 - val_accuracy: 0.8183\n",
      "Epoch 198/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 7.7033 - accuracy: 0.8433 - val_loss: 14.7801 - val_accuracy: 0.8139\n",
      "Epoch 199/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.9319 - accuracy: 0.8474 - val_loss: 15.1723 - val_accuracy: 0.8272\n",
      "Epoch 200/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.9484 - accuracy: 0.8429 - val_loss: 14.8730 - val_accuracy: 0.8257\n",
      "Epoch 201/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 7.9448 - accuracy: 0.8400 - val_loss: 15.0352 - val_accuracy: 0.8168\n",
      "Epoch 202/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 7.9770 - accuracy: 0.8441 - val_loss: 15.7582 - val_accuracy: 0.8198\n",
      "Epoch 203/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.6745 - accuracy: 0.8496 - val_loss: 15.0881 - val_accuracy: 0.8198\n",
      "Epoch 204/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.9056 - accuracy: 0.8437 - val_loss: 14.6918 - val_accuracy: 0.8198\n",
      "Epoch 205/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.7259 - accuracy: 0.8429 - val_loss: 14.8761 - val_accuracy: 0.8198\n",
      "Epoch 206/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.7875 - accuracy: 0.8459 - val_loss: 14.8985 - val_accuracy: 0.8065\n",
      "Epoch 207/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.7582 - accuracy: 0.8455 - val_loss: 14.7271 - val_accuracy: 0.8183\n",
      "Epoch 208/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.9692 - accuracy: 0.8441 - val_loss: 15.1662 - val_accuracy: 0.8139\n",
      "Epoch 209/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 7.6409 - accuracy: 0.8496 - val_loss: 14.5720 - val_accuracy: 0.8301\n",
      "Epoch 210/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.5322 - accuracy: 0.8466 - val_loss: 15.7218 - val_accuracy: 0.8168\n",
      "Epoch 211/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.6207 - accuracy: 0.8485 - val_loss: 14.7461 - val_accuracy: 0.8287\n",
      "Epoch 212/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.4788 - accuracy: 0.8525 - val_loss: 14.6146 - val_accuracy: 0.8257\n",
      "Epoch 213/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.6897 - accuracy: 0.8492 - val_loss: 15.2633 - val_accuracy: 0.8095\n",
      "Epoch 214/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.5274 - accuracy: 0.8474 - val_loss: 14.4118 - val_accuracy: 0.8316\n",
      "Epoch 215/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 7.5559 - accuracy: 0.8411 - val_loss: 14.5461 - val_accuracy: 0.8213\n",
      "Epoch 216/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.5021 - accuracy: 0.8500 - val_loss: 15.0089 - val_accuracy: 0.8227\n",
      "Epoch 217/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.2897 - accuracy: 0.8522 - val_loss: 14.6149 - val_accuracy: 0.8257\n",
      "Epoch 218/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.5150 - accuracy: 0.8437 - val_loss: 14.6265 - val_accuracy: 0.8272\n",
      "Epoch 219/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.3673 - accuracy: 0.8444 - val_loss: 14.3402 - val_accuracy: 0.8419\n",
      "Epoch 220/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.4540 - accuracy: 0.8441 - val_loss: 14.4544 - val_accuracy: 0.8183\n",
      "Epoch 221/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.3172 - accuracy: 0.8522 - val_loss: 14.7658 - val_accuracy: 0.8346\n",
      "Epoch 222/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.5906 - accuracy: 0.8477 - val_loss: 14.4713 - val_accuracy: 0.8183\n",
      "Epoch 223/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.2794 - accuracy: 0.8496 - val_loss: 14.6559 - val_accuracy: 0.8257\n",
      "Epoch 224/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.3340 - accuracy: 0.8477 - val_loss: 14.7274 - val_accuracy: 0.8242\n",
      "Epoch 225/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.6268 - accuracy: 0.8544 - val_loss: 14.5401 - val_accuracy: 0.8272\n",
      "Epoch 226/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.1731 - accuracy: 0.8522 - val_loss: 14.3630 - val_accuracy: 0.8316\n",
      "Epoch 227/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.3053 - accuracy: 0.8444 - val_loss: 14.3547 - val_accuracy: 0.8213\n",
      "Epoch 228/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.2970 - accuracy: 0.8481 - val_loss: 14.3385 - val_accuracy: 0.8213\n",
      "Epoch 229/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.2563 - accuracy: 0.8529 - val_loss: 14.6514 - val_accuracy: 0.8360\n",
      "Epoch 230/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.2891 - accuracy: 0.8470 - val_loss: 14.4857 - val_accuracy: 0.8301\n",
      "Epoch 231/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.1665 - accuracy: 0.8511 - val_loss: 14.2996 - val_accuracy: 0.8375\n",
      "Epoch 232/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.0959 - accuracy: 0.8492 - val_loss: 15.0995 - val_accuracy: 0.8272\n",
      "Epoch 233/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.2548 - accuracy: 0.8459 - val_loss: 13.8887 - val_accuracy: 0.8493\n",
      "Epoch 234/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.3094 - accuracy: 0.8503 - val_loss: 14.2714 - val_accuracy: 0.8360\n",
      "Epoch 235/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.1101 - accuracy: 0.8566 - val_loss: 13.8892 - val_accuracy: 0.8257\n",
      "Epoch 236/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.1892 - accuracy: 0.8518 - val_loss: 14.0212 - val_accuracy: 0.8287\n",
      "Epoch 237/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.1432 - accuracy: 0.8559 - val_loss: 14.1935 - val_accuracy: 0.8301\n",
      "Epoch 238/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.8173 - accuracy: 0.8559 - val_loss: 14.4925 - val_accuracy: 0.8360\n",
      "Epoch 239/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.9929 - accuracy: 0.8544 - val_loss: 14.3107 - val_accuracy: 0.8316\n",
      "Epoch 240/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.9552 - accuracy: 0.8544 - val_loss: 13.7146 - val_accuracy: 0.8360\n",
      "Epoch 241/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.9604 - accuracy: 0.8555 - val_loss: 14.1615 - val_accuracy: 0.8375\n",
      "Epoch 242/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.0555 - accuracy: 0.8555 - val_loss: 14.1190 - val_accuracy: 0.8331\n",
      "Epoch 243/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.9501 - accuracy: 0.8566 - val_loss: 14.2684 - val_accuracy: 0.8331\n",
      "Epoch 244/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.7794 - accuracy: 0.8551 - val_loss: 13.9816 - val_accuracy: 0.8242\n",
      "Epoch 245/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.8709 - accuracy: 0.8518 - val_loss: 13.8227 - val_accuracy: 0.8346\n",
      "Epoch 246/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 7.0248 - accuracy: 0.8559 - val_loss: 13.9865 - val_accuracy: 0.8375\n",
      "Epoch 247/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.8603 - accuracy: 0.8496 - val_loss: 13.4081 - val_accuracy: 0.8301\n",
      "Epoch 248/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.8318 - accuracy: 0.8514 - val_loss: 13.5235 - val_accuracy: 0.8523\n",
      "Epoch 249/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.9115 - accuracy: 0.8540 - val_loss: 13.3214 - val_accuracy: 0.8360\n",
      "Epoch 250/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.7297 - accuracy: 0.8588 - val_loss: 13.9794 - val_accuracy: 0.8375\n",
      "Epoch 251/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.9872 - accuracy: 0.8455 - val_loss: 14.1573 - val_accuracy: 0.8375\n",
      "Epoch 252/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.8441 - accuracy: 0.8577 - val_loss: 13.6410 - val_accuracy: 0.8375\n",
      "Epoch 253/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.6341 - accuracy: 0.8570 - val_loss: 13.5937 - val_accuracy: 0.8464\n",
      "Epoch 254/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.7010 - accuracy: 0.8592 - val_loss: 13.6196 - val_accuracy: 0.8405\n",
      "Epoch 255/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.8799 - accuracy: 0.8562 - val_loss: 14.2207 - val_accuracy: 0.8257\n",
      "Epoch 256/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.6424 - accuracy: 0.8518 - val_loss: 13.1786 - val_accuracy: 0.8419\n",
      "Epoch 257/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.6030 - accuracy: 0.8559 - val_loss: 13.5042 - val_accuracy: 0.8419\n",
      "Epoch 258/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.6582 - accuracy: 0.8599 - val_loss: 13.8342 - val_accuracy: 0.8405\n",
      "Epoch 259/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.7656 - accuracy: 0.8544 - val_loss: 14.0742 - val_accuracy: 0.8287\n",
      "Epoch 260/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.6616 - accuracy: 0.8548 - val_loss: 13.8562 - val_accuracy: 0.8360\n",
      "Epoch 261/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.5027 - accuracy: 0.8610 - val_loss: 13.5256 - val_accuracy: 0.8419\n",
      "Epoch 262/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.5564 - accuracy: 0.8566 - val_loss: 13.3502 - val_accuracy: 0.8434\n",
      "Epoch 263/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.5348 - accuracy: 0.8592 - val_loss: 13.5225 - val_accuracy: 0.8375\n",
      "Epoch 264/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.6384 - accuracy: 0.8540 - val_loss: 13.3621 - val_accuracy: 0.8434\n",
      "Epoch 265/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.4346 - accuracy: 0.8636 - val_loss: 13.2558 - val_accuracy: 0.8390\n",
      "Epoch 266/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.5809 - accuracy: 0.8592 - val_loss: 13.2919 - val_accuracy: 0.8479\n",
      "Epoch 267/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.3639 - accuracy: 0.8633 - val_loss: 13.2594 - val_accuracy: 0.8316\n",
      "Epoch 268/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.4922 - accuracy: 0.8570 - val_loss: 13.2960 - val_accuracy: 0.8301\n",
      "Epoch 269/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.6561 - accuracy: 0.8599 - val_loss: 13.2325 - val_accuracy: 0.8464\n",
      "Epoch 270/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.5518 - accuracy: 0.8607 - val_loss: 13.1565 - val_accuracy: 0.8287\n",
      "Epoch 271/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.5468 - accuracy: 0.8581 - val_loss: 13.3461 - val_accuracy: 0.8390\n",
      "Epoch 272/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.4429 - accuracy: 0.8618 - val_loss: 13.2041 - val_accuracy: 0.8479\n",
      "Epoch 273/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.3962 - accuracy: 0.8599 - val_loss: 13.0789 - val_accuracy: 0.8360\n",
      "Epoch 274/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.4544 - accuracy: 0.8570 - val_loss: 12.8772 - val_accuracy: 0.8508\n",
      "Epoch 275/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.3379 - accuracy: 0.8622 - val_loss: 12.9989 - val_accuracy: 0.8434\n",
      "Epoch 276/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 6.6487 - accuracy: 0.8577 - val_loss: 13.7034 - val_accuracy: 0.8287\n",
      "Epoch 277/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.3106 - accuracy: 0.8585 - val_loss: 12.8550 - val_accuracy: 0.8523\n",
      "Epoch 278/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.2506 - accuracy: 0.8673 - val_loss: 13.4669 - val_accuracy: 0.8434\n",
      "Epoch 279/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.4872 - accuracy: 0.8585 - val_loss: 13.7677 - val_accuracy: 0.8287\n",
      "Epoch 280/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1240 - accuracy: 0.8559 - val_loss: 12.8490 - val_accuracy: 0.8449\n",
      "Epoch 281/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 6.2877 - accuracy: 0.8610 - val_loss: 13.2855 - val_accuracy: 0.8464\n",
      "Epoch 282/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.4630 - accuracy: 0.8588 - val_loss: 12.8295 - val_accuracy: 0.8390\n",
      "Epoch 283/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1673 - accuracy: 0.8677 - val_loss: 12.7412 - val_accuracy: 0.8449\n",
      "Epoch 284/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1997 - accuracy: 0.8636 - val_loss: 12.5779 - val_accuracy: 0.8493\n",
      "Epoch 285/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.3278 - accuracy: 0.8562 - val_loss: 13.4364 - val_accuracy: 0.8419\n",
      "Epoch 286/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.2998 - accuracy: 0.8629 - val_loss: 12.9901 - val_accuracy: 0.8493\n",
      "Epoch 287/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 6.2319 - accuracy: 0.8629 - val_loss: 13.0415 - val_accuracy: 0.8434\n",
      "Epoch 288/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.3693 - accuracy: 0.8570 - val_loss: 12.4843 - val_accuracy: 0.8390\n",
      "Epoch 289/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.3035 - accuracy: 0.8640 - val_loss: 12.9981 - val_accuracy: 0.8419\n",
      "Epoch 290/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0723 - accuracy: 0.8607 - val_loss: 13.4181 - val_accuracy: 0.8479\n",
      "Epoch 291/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.2821 - accuracy: 0.8585 - val_loss: 12.7729 - val_accuracy: 0.8434\n",
      "Epoch 292/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1434 - accuracy: 0.8662 - val_loss: 13.0597 - val_accuracy: 0.8434\n",
      "Epoch 293/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.5658 - accuracy: 0.8577 - val_loss: 13.1216 - val_accuracy: 0.8493\n",
      "Epoch 294/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.2033 - accuracy: 0.8633 - val_loss: 12.4881 - val_accuracy: 0.8464\n",
      "Epoch 295/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.2223 - accuracy: 0.8647 - val_loss: 13.2011 - val_accuracy: 0.8390\n",
      "Epoch 296/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1237 - accuracy: 0.8659 - val_loss: 12.5691 - val_accuracy: 0.8346\n",
      "Epoch 297/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0203 - accuracy: 0.8640 - val_loss: 12.4985 - val_accuracy: 0.8449\n",
      "Epoch 298/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1411 - accuracy: 0.8574 - val_loss: 12.6367 - val_accuracy: 0.8464\n",
      "Epoch 299/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9168 - accuracy: 0.8695 - val_loss: 12.6530 - val_accuracy: 0.8419\n",
      "Epoch 300/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0538 - accuracy: 0.8588 - val_loss: 12.6794 - val_accuracy: 0.8360\n",
      "Epoch 301/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9080 - accuracy: 0.8610 - val_loss: 13.1452 - val_accuracy: 0.8360\n",
      "Epoch 302/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1500 - accuracy: 0.8625 - val_loss: 12.3047 - val_accuracy: 0.8493\n",
      "Epoch 303/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1988 - accuracy: 0.8655 - val_loss: 12.3764 - val_accuracy: 0.8419\n",
      "Epoch 304/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0466 - accuracy: 0.8585 - val_loss: 12.8091 - val_accuracy: 0.8375\n",
      "Epoch 305/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0790 - accuracy: 0.8655 - val_loss: 13.0190 - val_accuracy: 0.8390\n",
      "Epoch 306/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9551 - accuracy: 0.8588 - val_loss: 12.8325 - val_accuracy: 0.8405\n",
      "Epoch 307/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0843 - accuracy: 0.8618 - val_loss: 12.1957 - val_accuracy: 0.8434\n",
      "Epoch 308/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9282 - accuracy: 0.8633 - val_loss: 12.6276 - val_accuracy: 0.8434\n",
      "Epoch 309/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.8752 - accuracy: 0.8666 - val_loss: 12.5102 - val_accuracy: 0.8508\n",
      "Epoch 310/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.8841 - accuracy: 0.8633 - val_loss: 12.1657 - val_accuracy: 0.8390\n",
      "Epoch 311/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.1114 - accuracy: 0.8618 - val_loss: 12.1622 - val_accuracy: 0.8405\n",
      "Epoch 312/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0106 - accuracy: 0.8666 - val_loss: 12.2925 - val_accuracy: 0.8493\n",
      "Epoch 313/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0613 - accuracy: 0.8592 - val_loss: 13.1337 - val_accuracy: 0.8449\n",
      "Epoch 314/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 6.0003 - accuracy: 0.8636 - val_loss: 12.5093 - val_accuracy: 0.8390\n",
      "Epoch 315/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9351 - accuracy: 0.8644 - val_loss: 12.4105 - val_accuracy: 0.8434\n",
      "Epoch 316/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9705 - accuracy: 0.8625 - val_loss: 12.5492 - val_accuracy: 0.8375\n",
      "Epoch 317/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7843 - accuracy: 0.8655 - val_loss: 11.7200 - val_accuracy: 0.8538\n",
      "Epoch 318/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7954 - accuracy: 0.8644 - val_loss: 12.4368 - val_accuracy: 0.8493\n",
      "Epoch 319/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9469 - accuracy: 0.8581 - val_loss: 11.9241 - val_accuracy: 0.8479\n",
      "Epoch 320/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7829 - accuracy: 0.8647 - val_loss: 12.2631 - val_accuracy: 0.8360\n",
      "Epoch 321/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.8232 - accuracy: 0.8647 - val_loss: 11.6956 - val_accuracy: 0.8449\n",
      "Epoch 322/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.8365 - accuracy: 0.8592 - val_loss: 12.0406 - val_accuracy: 0.8493\n",
      "Epoch 323/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.8312 - accuracy: 0.8647 - val_loss: 11.7823 - val_accuracy: 0.8508\n",
      "Epoch 324/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.8648 - accuracy: 0.8622 - val_loss: 12.1855 - val_accuracy: 0.8464\n",
      "Epoch 325/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7376 - accuracy: 0.8688 - val_loss: 12.1133 - val_accuracy: 0.8464\n",
      "Epoch 326/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6692 - accuracy: 0.8684 - val_loss: 12.1560 - val_accuracy: 0.8419\n",
      "Epoch 327/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7284 - accuracy: 0.8677 - val_loss: 12.0867 - val_accuracy: 0.8464\n",
      "Epoch 328/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6464 - accuracy: 0.8622 - val_loss: 12.6857 - val_accuracy: 0.8479\n",
      "Epoch 329/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7909 - accuracy: 0.8692 - val_loss: 11.9224 - val_accuracy: 0.8508\n",
      "Epoch 330/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7230 - accuracy: 0.8714 - val_loss: 12.5886 - val_accuracy: 0.8493\n",
      "Epoch 331/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7758 - accuracy: 0.8659 - val_loss: 12.1850 - val_accuracy: 0.8552\n",
      "Epoch 332/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7034 - accuracy: 0.8688 - val_loss: 11.9790 - val_accuracy: 0.8464\n",
      "Epoch 333/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5881 - accuracy: 0.8636 - val_loss: 12.0592 - val_accuracy: 0.8523\n",
      "Epoch 334/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.9225 - accuracy: 0.8662 - val_loss: 12.3541 - val_accuracy: 0.8479\n",
      "Epoch 335/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7372 - accuracy: 0.8644 - val_loss: 11.9655 - val_accuracy: 0.8508\n",
      "Epoch 336/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6276 - accuracy: 0.8640 - val_loss: 11.7823 - val_accuracy: 0.8316\n",
      "Epoch 337/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6653 - accuracy: 0.8684 - val_loss: 11.6523 - val_accuracy: 0.8434\n",
      "Epoch 338/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7122 - accuracy: 0.8659 - val_loss: 11.9593 - val_accuracy: 0.8493\n",
      "Epoch 339/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7050 - accuracy: 0.8707 - val_loss: 12.2541 - val_accuracy: 0.8552\n",
      "Epoch 340/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7642 - accuracy: 0.8673 - val_loss: 12.1756 - val_accuracy: 0.8523\n",
      "Epoch 341/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6194 - accuracy: 0.8670 - val_loss: 11.7392 - val_accuracy: 0.8538\n",
      "Epoch 342/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6126 - accuracy: 0.8677 - val_loss: 11.5602 - val_accuracy: 0.8493\n",
      "Epoch 343/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3192 - accuracy: 0.8673 - val_loss: 11.8649 - val_accuracy: 0.8434\n",
      "Epoch 344/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5053 - accuracy: 0.8718 - val_loss: 12.0198 - val_accuracy: 0.8479\n",
      "Epoch 345/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7129 - accuracy: 0.8659 - val_loss: 11.6123 - val_accuracy: 0.8567\n",
      "Epoch 346/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7454 - accuracy: 0.8707 - val_loss: 11.6223 - val_accuracy: 0.8375\n",
      "Epoch 347/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7203 - accuracy: 0.8703 - val_loss: 11.3453 - val_accuracy: 0.8582\n",
      "Epoch 348/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5130 - accuracy: 0.8670 - val_loss: 11.7963 - val_accuracy: 0.8346\n",
      "Epoch 349/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4714 - accuracy: 0.8695 - val_loss: 12.0910 - val_accuracy: 0.8419\n",
      "Epoch 350/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6376 - accuracy: 0.8673 - val_loss: 11.5919 - val_accuracy: 0.8538\n",
      "Epoch 351/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4264 - accuracy: 0.8707 - val_loss: 12.1009 - val_accuracy: 0.8419\n",
      "Epoch 352/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4590 - accuracy: 0.8710 - val_loss: 12.1282 - val_accuracy: 0.8538\n",
      "Epoch 353/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 5.6199 - accuracy: 0.8710 - val_loss: 11.5629 - val_accuracy: 0.8479\n",
      "Epoch 354/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3504 - accuracy: 0.8681 - val_loss: 12.1003 - val_accuracy: 0.8390\n",
      "Epoch 355/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5324 - accuracy: 0.8625 - val_loss: 11.7463 - val_accuracy: 0.8508\n",
      "Epoch 356/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4231 - accuracy: 0.8732 - val_loss: 11.7918 - val_accuracy: 0.8464\n",
      "Epoch 357/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5274 - accuracy: 0.8681 - val_loss: 12.2464 - val_accuracy: 0.8538\n",
      "Epoch 358/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6241 - accuracy: 0.8707 - val_loss: 11.4011 - val_accuracy: 0.8479\n",
      "Epoch 359/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5288 - accuracy: 0.8662 - val_loss: 11.4194 - val_accuracy: 0.8508\n",
      "Epoch 360/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5107 - accuracy: 0.8692 - val_loss: 11.6376 - val_accuracy: 0.8538\n",
      "Epoch 361/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4473 - accuracy: 0.8659 - val_loss: 11.6144 - val_accuracy: 0.8523\n",
      "Epoch 362/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.5323 - accuracy: 0.8625 - val_loss: 11.5789 - val_accuracy: 0.8552\n",
      "Epoch 363/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4228 - accuracy: 0.8703 - val_loss: 11.4049 - val_accuracy: 0.8464\n",
      "Epoch 364/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3507 - accuracy: 0.8670 - val_loss: 11.9412 - val_accuracy: 0.8552\n",
      "Epoch 365/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4240 - accuracy: 0.8692 - val_loss: 11.7711 - val_accuracy: 0.8612\n",
      "Epoch 366/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.7308 - accuracy: 0.8662 - val_loss: 11.4056 - val_accuracy: 0.8626\n",
      "Epoch 367/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.6534 - accuracy: 0.8747 - val_loss: 11.1300 - val_accuracy: 0.8479\n",
      "Epoch 368/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3476 - accuracy: 0.8699 - val_loss: 11.2676 - val_accuracy: 0.8567\n",
      "Epoch 369/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2560 - accuracy: 0.8729 - val_loss: 10.9618 - val_accuracy: 0.8715\n",
      "Epoch 370/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3331 - accuracy: 0.8744 - val_loss: 11.2070 - val_accuracy: 0.8493\n",
      "Epoch 371/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3900 - accuracy: 0.8714 - val_loss: 11.6859 - val_accuracy: 0.8493\n",
      "Epoch 372/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2568 - accuracy: 0.8729 - val_loss: 11.0662 - val_accuracy: 0.8523\n",
      "Epoch 373/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3545 - accuracy: 0.8688 - val_loss: 11.1729 - val_accuracy: 0.8538\n",
      "Epoch 374/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3967 - accuracy: 0.8681 - val_loss: 11.2755 - val_accuracy: 0.8493\n",
      "Epoch 375/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3478 - accuracy: 0.8666 - val_loss: 11.9091 - val_accuracy: 0.8552\n",
      "Epoch 376/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1327 - accuracy: 0.8710 - val_loss: 11.3221 - val_accuracy: 0.8582\n",
      "Epoch 377/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4672 - accuracy: 0.8670 - val_loss: 11.0037 - val_accuracy: 0.8597\n",
      "Epoch 378/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.4902 - accuracy: 0.8714 - val_loss: 11.3735 - val_accuracy: 0.8567\n",
      "Epoch 379/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1574 - accuracy: 0.8740 - val_loss: 11.3902 - val_accuracy: 0.8567\n",
      "Epoch 380/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0090 - accuracy: 0.8718 - val_loss: 11.5252 - val_accuracy: 0.8434\n",
      "Epoch 381/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2828 - accuracy: 0.8732 - val_loss: 11.5353 - val_accuracy: 0.8390\n",
      "Epoch 382/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2792 - accuracy: 0.8695 - val_loss: 11.1156 - val_accuracy: 0.8582\n",
      "Epoch 383/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0815 - accuracy: 0.8699 - val_loss: 11.0770 - val_accuracy: 0.8493\n",
      "Epoch 384/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3196 - accuracy: 0.8703 - val_loss: 11.2750 - val_accuracy: 0.8464\n",
      "Epoch 385/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1721 - accuracy: 0.8684 - val_loss: 11.1222 - val_accuracy: 0.8523\n",
      "Epoch 386/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2919 - accuracy: 0.8703 - val_loss: 10.9784 - val_accuracy: 0.8597\n",
      "Epoch 387/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2682 - accuracy: 0.8721 - val_loss: 11.3660 - val_accuracy: 0.8685\n",
      "Epoch 388/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1995 - accuracy: 0.8703 - val_loss: 11.2511 - val_accuracy: 0.8523\n",
      "Epoch 389/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2579 - accuracy: 0.8721 - val_loss: 11.2962 - val_accuracy: 0.8508\n",
      "Epoch 390/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2772 - accuracy: 0.8688 - val_loss: 11.6648 - val_accuracy: 0.8538\n",
      "Epoch 391/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2533 - accuracy: 0.8666 - val_loss: 11.1162 - val_accuracy: 0.8582\n",
      "Epoch 392/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0434 - accuracy: 0.8707 - val_loss: 11.1587 - val_accuracy: 0.8523\n",
      "Epoch 393/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2869 - accuracy: 0.8707 - val_loss: 11.6543 - val_accuracy: 0.8464\n",
      "Epoch 394/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2809 - accuracy: 0.8744 - val_loss: 11.3317 - val_accuracy: 0.8582\n",
      "Epoch 395/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1030 - accuracy: 0.8714 - val_loss: 11.0822 - val_accuracy: 0.8641\n",
      "Epoch 396/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1364 - accuracy: 0.8725 - val_loss: 11.5974 - val_accuracy: 0.8493\n",
      "Epoch 397/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.3081 - accuracy: 0.8718 - val_loss: 11.5611 - val_accuracy: 0.8552\n",
      "Epoch 398/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0955 - accuracy: 0.8732 - val_loss: 10.9530 - val_accuracy: 0.8597\n",
      "Epoch 399/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2223 - accuracy: 0.8673 - val_loss: 10.9215 - val_accuracy: 0.8641\n",
      "Epoch 400/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2068 - accuracy: 0.8688 - val_loss: 11.3496 - val_accuracy: 0.8493\n",
      "Epoch 401/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2504 - accuracy: 0.8688 - val_loss: 11.7110 - val_accuracy: 0.8434\n",
      "Epoch 402/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2221 - accuracy: 0.8747 - val_loss: 12.1571 - val_accuracy: 0.8567\n",
      "Epoch 403/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2171 - accuracy: 0.8710 - val_loss: 11.6908 - val_accuracy: 0.8449\n",
      "Epoch 404/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2583 - accuracy: 0.8684 - val_loss: 11.4520 - val_accuracy: 0.8538\n",
      "Epoch 405/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0409 - accuracy: 0.8721 - val_loss: 10.7801 - val_accuracy: 0.8597\n",
      "Epoch 406/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1468 - accuracy: 0.8688 - val_loss: 11.9403 - val_accuracy: 0.8508\n",
      "Epoch 407/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1013 - accuracy: 0.8736 - val_loss: 11.3037 - val_accuracy: 0.8567\n",
      "Epoch 408/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1165 - accuracy: 0.8732 - val_loss: 11.5345 - val_accuracy: 0.8538\n",
      "Epoch 409/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0146 - accuracy: 0.8769 - val_loss: 10.9271 - val_accuracy: 0.8552\n",
      "Epoch 410/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0254 - accuracy: 0.8744 - val_loss: 11.2721 - val_accuracy: 0.8612\n",
      "Epoch 411/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2713 - accuracy: 0.8703 - val_loss: 10.8191 - val_accuracy: 0.8597\n",
      "Epoch 412/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1300 - accuracy: 0.8721 - val_loss: 11.2485 - val_accuracy: 0.8538\n",
      "Epoch 413/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1201 - accuracy: 0.8725 - val_loss: 11.2894 - val_accuracy: 0.8626\n",
      "Epoch 414/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0050 - accuracy: 0.8714 - val_loss: 10.9741 - val_accuracy: 0.8582\n",
      "Epoch 415/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1375 - accuracy: 0.8729 - val_loss: 10.8365 - val_accuracy: 0.8538\n",
      "Epoch 416/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9882 - accuracy: 0.8677 - val_loss: 11.6740 - val_accuracy: 0.8449\n",
      "Epoch 417/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2381 - accuracy: 0.8662 - val_loss: 11.1225 - val_accuracy: 0.8567\n",
      "Epoch 418/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9819 - accuracy: 0.8747 - val_loss: 11.1159 - val_accuracy: 0.8597\n",
      "Epoch 419/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9194 - accuracy: 0.8721 - val_loss: 10.9437 - val_accuracy: 0.8493\n",
      "Epoch 420/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9715 - accuracy: 0.8758 - val_loss: 11.2994 - val_accuracy: 0.8567\n",
      "Epoch 421/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9352 - accuracy: 0.8721 - val_loss: 11.8101 - val_accuracy: 0.8612\n",
      "Epoch 422/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0762 - accuracy: 0.8766 - val_loss: 11.6614 - val_accuracy: 0.8552\n",
      "Epoch 423/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9808 - accuracy: 0.8740 - val_loss: 10.8402 - val_accuracy: 0.8671\n",
      "Epoch 424/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0408 - accuracy: 0.8710 - val_loss: 10.6375 - val_accuracy: 0.8612\n",
      "Epoch 425/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9755 - accuracy: 0.8755 - val_loss: 11.3776 - val_accuracy: 0.8641\n",
      "Epoch 426/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1004 - accuracy: 0.8758 - val_loss: 10.9005 - val_accuracy: 0.8612\n",
      "Epoch 427/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9670 - accuracy: 0.8725 - val_loss: 11.0546 - val_accuracy: 0.8464\n",
      "Epoch 428/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8926 - accuracy: 0.8729 - val_loss: 10.8236 - val_accuracy: 0.8552\n",
      "Epoch 429/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1427 - accuracy: 0.8744 - val_loss: 10.7944 - val_accuracy: 0.8612\n",
      "Epoch 430/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0275 - accuracy: 0.8736 - val_loss: 10.9595 - val_accuracy: 0.8479\n",
      "Epoch 431/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9403 - accuracy: 0.8707 - val_loss: 10.6060 - val_accuracy: 0.8508\n",
      "Epoch 432/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0507 - accuracy: 0.8721 - val_loss: 11.3190 - val_accuracy: 0.8508\n",
      "Epoch 433/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0809 - accuracy: 0.8703 - val_loss: 11.0354 - val_accuracy: 0.8508\n",
      "Epoch 434/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0487 - accuracy: 0.8710 - val_loss: 11.2150 - val_accuracy: 0.8523\n",
      "Epoch 435/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9865 - accuracy: 0.8677 - val_loss: 10.9389 - val_accuracy: 0.8641\n",
      "Epoch 436/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1549 - accuracy: 0.8695 - val_loss: 10.3494 - val_accuracy: 0.8626\n",
      "Epoch 437/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8242 - accuracy: 0.8695 - val_loss: 10.6565 - val_accuracy: 0.8671\n",
      "Epoch 438/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0463 - accuracy: 0.8684 - val_loss: 10.7694 - val_accuracy: 0.8567\n",
      "Epoch 439/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9292 - accuracy: 0.8692 - val_loss: 10.7729 - val_accuracy: 0.8508\n",
      "Epoch 440/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8844 - accuracy: 0.8725 - val_loss: 10.4992 - val_accuracy: 0.8567\n",
      "Epoch 441/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8104 - accuracy: 0.8769 - val_loss: 10.6627 - val_accuracy: 0.8538\n",
      "Epoch 442/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8142 - accuracy: 0.8758 - val_loss: 10.4688 - val_accuracy: 0.8567\n",
      "Epoch 443/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8345 - accuracy: 0.8718 - val_loss: 10.7752 - val_accuracy: 0.8479\n",
      "Epoch 444/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8686 - accuracy: 0.8725 - val_loss: 10.4351 - val_accuracy: 0.8656\n",
      "Epoch 445/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8812 - accuracy: 0.8714 - val_loss: 10.4074 - val_accuracy: 0.8656\n",
      "Epoch 446/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8873 - accuracy: 0.8681 - val_loss: 10.2777 - val_accuracy: 0.8641\n",
      "Epoch 447/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.1031 - accuracy: 0.8729 - val_loss: 11.0719 - val_accuracy: 0.8508\n",
      "Epoch 448/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9689 - accuracy: 0.8740 - val_loss: 11.3352 - val_accuracy: 0.8479\n",
      "Epoch 449/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8347 - accuracy: 0.8740 - val_loss: 10.4968 - val_accuracy: 0.8567\n",
      "Epoch 450/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7494 - accuracy: 0.8740 - val_loss: 10.7580 - val_accuracy: 0.8523\n",
      "Epoch 451/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8764 - accuracy: 0.8740 - val_loss: 10.7758 - val_accuracy: 0.8479\n",
      "Epoch 452/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7302 - accuracy: 0.8714 - val_loss: 10.8779 - val_accuracy: 0.8567\n",
      "Epoch 453/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.2730 - accuracy: 0.8744 - val_loss: 10.8801 - val_accuracy: 0.8626\n",
      "Epoch 454/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6689 - accuracy: 0.8766 - val_loss: 10.4621 - val_accuracy: 0.8597\n",
      "Epoch 455/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7033 - accuracy: 0.8732 - val_loss: 10.3639 - val_accuracy: 0.8552\n",
      "Epoch 456/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8550 - accuracy: 0.8755 - val_loss: 11.2900 - val_accuracy: 0.8552\n",
      "Epoch 457/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 5.0489 - accuracy: 0.8721 - val_loss: 11.2345 - val_accuracy: 0.8523\n",
      "Epoch 458/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7073 - accuracy: 0.8784 - val_loss: 10.5982 - val_accuracy: 0.8538\n",
      "Epoch 459/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9398 - accuracy: 0.8699 - val_loss: 10.9455 - val_accuracy: 0.8390\n",
      "Epoch 460/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6612 - accuracy: 0.8725 - val_loss: 10.8260 - val_accuracy: 0.8508\n",
      "Epoch 461/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9143 - accuracy: 0.8769 - val_loss: 10.9179 - val_accuracy: 0.8464\n",
      "Epoch 462/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7539 - accuracy: 0.8732 - val_loss: 11.1082 - val_accuracy: 0.8552\n",
      "Epoch 463/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7473 - accuracy: 0.8729 - val_loss: 10.3692 - val_accuracy: 0.8552\n",
      "Epoch 464/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6738 - accuracy: 0.8725 - val_loss: 10.4678 - val_accuracy: 0.8671\n",
      "Epoch 465/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6798 - accuracy: 0.8744 - val_loss: 10.4650 - val_accuracy: 0.8434\n",
      "Epoch 466/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9702 - accuracy: 0.8740 - val_loss: 10.2401 - val_accuracy: 0.8626\n",
      "Epoch 467/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5860 - accuracy: 0.8747 - val_loss: 10.9037 - val_accuracy: 0.8656\n",
      "Epoch 468/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6676 - accuracy: 0.8744 - val_loss: 10.3856 - val_accuracy: 0.8552\n",
      "Epoch 469/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7424 - accuracy: 0.8736 - val_loss: 10.5811 - val_accuracy: 0.8552\n",
      "Epoch 470/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8590 - accuracy: 0.8710 - val_loss: 10.6405 - val_accuracy: 0.8523\n",
      "Epoch 471/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6841 - accuracy: 0.8718 - val_loss: 10.4864 - val_accuracy: 0.8464\n",
      "Epoch 472/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8750 - accuracy: 0.8751 - val_loss: 10.2573 - val_accuracy: 0.8479\n",
      "Epoch 473/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7992 - accuracy: 0.8762 - val_loss: 10.2149 - val_accuracy: 0.8538\n",
      "Epoch 474/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7181 - accuracy: 0.8725 - val_loss: 10.3239 - val_accuracy: 0.8479\n",
      "Epoch 475/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7164 - accuracy: 0.8747 - val_loss: 10.1855 - val_accuracy: 0.8538\n",
      "Epoch 476/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6482 - accuracy: 0.8736 - val_loss: 10.5611 - val_accuracy: 0.8493\n",
      "Epoch 477/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7704 - accuracy: 0.8732 - val_loss: 11.2802 - val_accuracy: 0.8479\n",
      "Epoch 478/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6892 - accuracy: 0.8751 - val_loss: 10.7038 - val_accuracy: 0.8419\n",
      "Epoch 479/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6552 - accuracy: 0.8762 - val_loss: 10.6548 - val_accuracy: 0.8567\n",
      "Epoch 480/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7091 - accuracy: 0.8721 - val_loss: 10.6278 - val_accuracy: 0.8508\n",
      "Epoch 481/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6475 - accuracy: 0.8695 - val_loss: 10.2529 - val_accuracy: 0.8523\n",
      "Epoch 482/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9501 - accuracy: 0.8666 - val_loss: 10.3479 - val_accuracy: 0.8464\n",
      "Epoch 483/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7728 - accuracy: 0.8703 - val_loss: 10.3689 - val_accuracy: 0.8567\n",
      "Epoch 484/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5267 - accuracy: 0.8755 - val_loss: 10.4841 - val_accuracy: 0.8434\n",
      "Epoch 485/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7547 - accuracy: 0.8744 - val_loss: 10.0621 - val_accuracy: 0.8552\n",
      "Epoch 486/998\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 4.7628 - accuracy: 0.8769 - val_loss: 10.7805 - val_accuracy: 0.8493\n",
      "Epoch 487/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6895 - accuracy: 0.8751 - val_loss: 10.3672 - val_accuracy: 0.8479\n",
      "Epoch 488/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8300 - accuracy: 0.8729 - val_loss: 9.9829 - val_accuracy: 0.8582\n",
      "Epoch 489/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5804 - accuracy: 0.8792 - val_loss: 10.4148 - val_accuracy: 0.8493\n",
      "Epoch 490/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8826 - accuracy: 0.8729 - val_loss: 10.2667 - val_accuracy: 0.8538\n",
      "Epoch 491/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7118 - accuracy: 0.8758 - val_loss: 10.0340 - val_accuracy: 0.8552\n",
      "Epoch 492/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5426 - accuracy: 0.8710 - val_loss: 10.1160 - val_accuracy: 0.8508\n",
      "Epoch 493/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7594 - accuracy: 0.8751 - val_loss: 9.7866 - val_accuracy: 0.8523\n",
      "Epoch 494/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6148 - accuracy: 0.8751 - val_loss: 10.2581 - val_accuracy: 0.8464\n",
      "Epoch 495/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5338 - accuracy: 0.8777 - val_loss: 10.2434 - val_accuracy: 0.8552\n",
      "Epoch 496/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.9036 - accuracy: 0.8725 - val_loss: 10.5170 - val_accuracy: 0.8464\n",
      "Epoch 497/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5056 - accuracy: 0.8725 - val_loss: 9.7394 - val_accuracy: 0.8597\n",
      "Epoch 498/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5321 - accuracy: 0.8758 - val_loss: 10.2027 - val_accuracy: 0.8567\n",
      "Epoch 499/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8759 - accuracy: 0.8725 - val_loss: 10.4231 - val_accuracy: 0.8493\n",
      "Epoch 500/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6227 - accuracy: 0.8773 - val_loss: 10.5893 - val_accuracy: 0.8597\n",
      "Epoch 501/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5797 - accuracy: 0.8810 - val_loss: 10.1244 - val_accuracy: 0.8405\n",
      "Epoch 502/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6277 - accuracy: 0.8747 - val_loss: 10.2947 - val_accuracy: 0.8493\n",
      "Epoch 503/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4801 - accuracy: 0.8755 - val_loss: 10.0836 - val_accuracy: 0.8552\n",
      "Epoch 504/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5222 - accuracy: 0.8751 - val_loss: 10.0117 - val_accuracy: 0.8449\n",
      "Epoch 505/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6409 - accuracy: 0.8714 - val_loss: 10.4972 - val_accuracy: 0.8523\n",
      "Epoch 506/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5863 - accuracy: 0.8780 - val_loss: 10.4318 - val_accuracy: 0.8449\n",
      "Epoch 507/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4910 - accuracy: 0.8792 - val_loss: 10.2965 - val_accuracy: 0.8508\n",
      "Epoch 508/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.8099 - accuracy: 0.8766 - val_loss: 10.6246 - val_accuracy: 0.8464\n",
      "Epoch 509/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5623 - accuracy: 0.8758 - val_loss: 9.8773 - val_accuracy: 0.8449\n",
      "Epoch 510/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4263 - accuracy: 0.8736 - val_loss: 10.2526 - val_accuracy: 0.8464\n",
      "Epoch 511/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5247 - accuracy: 0.8810 - val_loss: 9.7772 - val_accuracy: 0.8523\n",
      "Epoch 512/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6736 - accuracy: 0.8725 - val_loss: 10.2346 - val_accuracy: 0.8493\n",
      "Epoch 513/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4436 - accuracy: 0.8740 - val_loss: 10.1643 - val_accuracy: 0.8523\n",
      "Epoch 514/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4327 - accuracy: 0.8740 - val_loss: 10.4099 - val_accuracy: 0.8508\n",
      "Epoch 515/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4960 - accuracy: 0.8747 - val_loss: 10.6128 - val_accuracy: 0.8346\n",
      "Epoch 516/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4516 - accuracy: 0.8747 - val_loss: 10.3024 - val_accuracy: 0.8493\n",
      "Epoch 517/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3822 - accuracy: 0.8758 - val_loss: 9.8279 - val_accuracy: 0.8567\n",
      "Epoch 518/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4613 - accuracy: 0.8751 - val_loss: 9.8855 - val_accuracy: 0.8419\n",
      "Epoch 519/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6869 - accuracy: 0.8707 - val_loss: 10.5148 - val_accuracy: 0.8257\n",
      "Epoch 520/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4985 - accuracy: 0.8721 - val_loss: 9.8604 - val_accuracy: 0.8434\n",
      "Epoch 521/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7232 - accuracy: 0.8755 - val_loss: 9.8885 - val_accuracy: 0.8449\n",
      "Epoch 522/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4572 - accuracy: 0.8777 - val_loss: 10.1981 - val_accuracy: 0.8508\n",
      "Epoch 523/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5463 - accuracy: 0.8795 - val_loss: 9.9141 - val_accuracy: 0.8582\n",
      "Epoch 524/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3110 - accuracy: 0.8729 - val_loss: 10.2543 - val_accuracy: 0.8434\n",
      "Epoch 525/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4432 - accuracy: 0.8788 - val_loss: 10.3221 - val_accuracy: 0.8464\n",
      "Epoch 526/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4919 - accuracy: 0.8777 - val_loss: 9.8966 - val_accuracy: 0.8346\n",
      "Epoch 527/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4320 - accuracy: 0.8699 - val_loss: 9.9729 - val_accuracy: 0.8493\n",
      "Epoch 528/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4871 - accuracy: 0.8755 - val_loss: 10.0992 - val_accuracy: 0.8508\n",
      "Epoch 529/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5661 - accuracy: 0.8788 - val_loss: 10.0912 - val_accuracy: 0.8597\n",
      "Epoch 530/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5841 - accuracy: 0.8729 - val_loss: 10.4337 - val_accuracy: 0.8316\n",
      "Epoch 531/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5951 - accuracy: 0.8777 - val_loss: 10.1701 - val_accuracy: 0.8597\n",
      "Epoch 532/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5688 - accuracy: 0.8744 - val_loss: 9.9020 - val_accuracy: 0.8479\n",
      "Epoch 533/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3728 - accuracy: 0.8721 - val_loss: 10.0489 - val_accuracy: 0.8464\n",
      "Epoch 534/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3982 - accuracy: 0.8740 - val_loss: 10.2835 - val_accuracy: 0.8523\n",
      "Epoch 535/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4546 - accuracy: 0.8803 - val_loss: 9.8070 - val_accuracy: 0.8257\n",
      "Epoch 536/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.7296 - accuracy: 0.8710 - val_loss: 10.2442 - val_accuracy: 0.8449\n",
      "Epoch 537/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5377 - accuracy: 0.8795 - val_loss: 10.0800 - val_accuracy: 0.8434\n",
      "Epoch 538/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4342 - accuracy: 0.8769 - val_loss: 9.6678 - val_accuracy: 0.8493\n",
      "Epoch 539/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5141 - accuracy: 0.8795 - val_loss: 10.1162 - val_accuracy: 0.8552\n",
      "Epoch 540/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4796 - accuracy: 0.8755 - val_loss: 9.7930 - val_accuracy: 0.8479\n",
      "Epoch 541/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6009 - accuracy: 0.8725 - val_loss: 10.3079 - val_accuracy: 0.8464\n",
      "Epoch 542/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3838 - accuracy: 0.8744 - val_loss: 10.0158 - val_accuracy: 0.8464\n",
      "Epoch 543/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4774 - accuracy: 0.8788 - val_loss: 10.0307 - val_accuracy: 0.8479\n",
      "Epoch 544/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3616 - accuracy: 0.8721 - val_loss: 9.7721 - val_accuracy: 0.8523\n",
      "Epoch 545/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3125 - accuracy: 0.8784 - val_loss: 10.0829 - val_accuracy: 0.8479\n",
      "Epoch 546/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3778 - accuracy: 0.8788 - val_loss: 9.8774 - val_accuracy: 0.8523\n",
      "Epoch 547/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3931 - accuracy: 0.8758 - val_loss: 10.0892 - val_accuracy: 0.8582\n",
      "Epoch 548/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3084 - accuracy: 0.8769 - val_loss: 9.6818 - val_accuracy: 0.8523\n",
      "Epoch 549/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3443 - accuracy: 0.8725 - val_loss: 10.2361 - val_accuracy: 0.8552\n",
      "Epoch 550/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4493 - accuracy: 0.8795 - val_loss: 9.6851 - val_accuracy: 0.8567\n",
      "Epoch 551/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3204 - accuracy: 0.8766 - val_loss: 10.1023 - val_accuracy: 0.8508\n",
      "Epoch 552/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2585 - accuracy: 0.8721 - val_loss: 9.8004 - val_accuracy: 0.8434\n",
      "Epoch 553/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1950 - accuracy: 0.8725 - val_loss: 9.4209 - val_accuracy: 0.8567\n",
      "Epoch 554/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2838 - accuracy: 0.8795 - val_loss: 9.7185 - val_accuracy: 0.8538\n",
      "Epoch 555/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2965 - accuracy: 0.8762 - val_loss: 9.5338 - val_accuracy: 0.8523\n",
      "Epoch 556/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.4048 - accuracy: 0.8766 - val_loss: 9.9911 - val_accuracy: 0.8464\n",
      "Epoch 557/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4805 - accuracy: 0.8710 - val_loss: 9.5982 - val_accuracy: 0.8464\n",
      "Epoch 558/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5111 - accuracy: 0.8729 - val_loss: 10.4187 - val_accuracy: 0.8508\n",
      "Epoch 559/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4781 - accuracy: 0.8773 - val_loss: 9.4794 - val_accuracy: 0.8493\n",
      "Epoch 560/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2775 - accuracy: 0.8762 - val_loss: 10.1939 - val_accuracy: 0.8567\n",
      "Epoch 561/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3461 - accuracy: 0.8758 - val_loss: 9.3975 - val_accuracy: 0.8582\n",
      "Epoch 562/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6332 - accuracy: 0.8806 - val_loss: 9.9034 - val_accuracy: 0.8493\n",
      "Epoch 563/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3028 - accuracy: 0.8769 - val_loss: 10.0644 - val_accuracy: 0.8582\n",
      "Epoch 564/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3443 - accuracy: 0.8714 - val_loss: 9.6980 - val_accuracy: 0.8597\n",
      "Epoch 565/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3957 - accuracy: 0.8792 - val_loss: 9.6081 - val_accuracy: 0.8523\n",
      "Epoch 566/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4396 - accuracy: 0.8721 - val_loss: 9.4133 - val_accuracy: 0.8552\n",
      "Epoch 567/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2202 - accuracy: 0.8762 - val_loss: 10.0384 - val_accuracy: 0.8434\n",
      "Epoch 568/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.5617 - accuracy: 0.8784 - val_loss: 9.8370 - val_accuracy: 0.8301\n",
      "Epoch 569/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3815 - accuracy: 0.8766 - val_loss: 10.4896 - val_accuracy: 0.8316\n",
      "Epoch 570/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3840 - accuracy: 0.8766 - val_loss: 9.7851 - val_accuracy: 0.8552\n",
      "Epoch 571/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2823 - accuracy: 0.8821 - val_loss: 10.0357 - val_accuracy: 0.8419\n",
      "Epoch 572/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2515 - accuracy: 0.8762 - val_loss: 9.5891 - val_accuracy: 0.8538\n",
      "Epoch 573/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.6138 - accuracy: 0.8769 - val_loss: 10.3139 - val_accuracy: 0.8449\n",
      "Epoch 574/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3116 - accuracy: 0.8762 - val_loss: 9.5537 - val_accuracy: 0.8552\n",
      "Epoch 575/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1672 - accuracy: 0.8784 - val_loss: 9.2920 - val_accuracy: 0.8538\n",
      "Epoch 576/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.4474 - accuracy: 0.8766 - val_loss: 9.9809 - val_accuracy: 0.8567\n",
      "Epoch 577/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3290 - accuracy: 0.8714 - val_loss: 9.2880 - val_accuracy: 0.8538\n",
      "Epoch 578/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1145 - accuracy: 0.8736 - val_loss: 9.5839 - val_accuracy: 0.8538\n",
      "Epoch 579/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1698 - accuracy: 0.8758 - val_loss: 9.7273 - val_accuracy: 0.8582\n",
      "Epoch 580/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2614 - accuracy: 0.8784 - val_loss: 9.5538 - val_accuracy: 0.8612\n",
      "Epoch 581/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2187 - accuracy: 0.8758 - val_loss: 10.2772 - val_accuracy: 0.8523\n",
      "Epoch 582/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1385 - accuracy: 0.8773 - val_loss: 9.4345 - val_accuracy: 0.8597\n",
      "Epoch 583/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2362 - accuracy: 0.8788 - val_loss: 9.4893 - val_accuracy: 0.8479\n",
      "Epoch 584/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2229 - accuracy: 0.8777 - val_loss: 9.4732 - val_accuracy: 0.8464\n",
      "Epoch 585/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1963 - accuracy: 0.8751 - val_loss: 9.6016 - val_accuracy: 0.8552\n",
      "Epoch 586/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2375 - accuracy: 0.8769 - val_loss: 9.4415 - val_accuracy: 0.8538\n",
      "Epoch 587/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0997 - accuracy: 0.8788 - val_loss: 9.6041 - val_accuracy: 0.8449\n",
      "Epoch 588/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1807 - accuracy: 0.8777 - val_loss: 9.6526 - val_accuracy: 0.8464\n",
      "Epoch 589/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1306 - accuracy: 0.8769 - val_loss: 9.5798 - val_accuracy: 0.8508\n",
      "Epoch 590/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0853 - accuracy: 0.8766 - val_loss: 9.6881 - val_accuracy: 0.8449\n",
      "Epoch 591/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3433 - accuracy: 0.8747 - val_loss: 9.8329 - val_accuracy: 0.8508\n",
      "Epoch 592/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0699 - accuracy: 0.8780 - val_loss: 9.6723 - val_accuracy: 0.8552\n",
      "Epoch 593/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2285 - accuracy: 0.8777 - val_loss: 9.3474 - val_accuracy: 0.8464\n",
      "Epoch 594/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2905 - accuracy: 0.8758 - val_loss: 9.4357 - val_accuracy: 0.8597\n",
      "Epoch 595/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0520 - accuracy: 0.8788 - val_loss: 9.1407 - val_accuracy: 0.8597\n",
      "Epoch 596/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2284 - accuracy: 0.8795 - val_loss: 9.3252 - val_accuracy: 0.8434\n",
      "Epoch 597/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2435 - accuracy: 0.8710 - val_loss: 9.4382 - val_accuracy: 0.8493\n",
      "Epoch 598/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2312 - accuracy: 0.8695 - val_loss: 9.8059 - val_accuracy: 0.8523\n",
      "Epoch 599/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3883 - accuracy: 0.8795 - val_loss: 9.3922 - val_accuracy: 0.8508\n",
      "Epoch 600/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0775 - accuracy: 0.8799 - val_loss: 9.1624 - val_accuracy: 0.8493\n",
      "Epoch 601/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3577 - accuracy: 0.8751 - val_loss: 9.4705 - val_accuracy: 0.8464\n",
      "Epoch 602/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0860 - accuracy: 0.8758 - val_loss: 9.3085 - val_accuracy: 0.8523\n",
      "Epoch 603/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1276 - accuracy: 0.8758 - val_loss: 9.7670 - val_accuracy: 0.8508\n",
      "Epoch 604/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2260 - accuracy: 0.8732 - val_loss: 9.5405 - val_accuracy: 0.8552\n",
      "Epoch 605/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2365 - accuracy: 0.8729 - val_loss: 9.3412 - val_accuracy: 0.8449\n",
      "Epoch 606/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1971 - accuracy: 0.8725 - val_loss: 9.4435 - val_accuracy: 0.8493\n",
      "Epoch 607/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9643 - accuracy: 0.8773 - val_loss: 9.3943 - val_accuracy: 0.8464\n",
      "Epoch 608/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0887 - accuracy: 0.8795 - val_loss: 9.5384 - val_accuracy: 0.8479\n",
      "Epoch 609/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1010 - accuracy: 0.8780 - val_loss: 9.5984 - val_accuracy: 0.8434\n",
      "Epoch 610/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0368 - accuracy: 0.8769 - val_loss: 9.6931 - val_accuracy: 0.8449\n",
      "Epoch 611/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0694 - accuracy: 0.8795 - val_loss: 9.6536 - val_accuracy: 0.8272\n",
      "Epoch 612/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2058 - accuracy: 0.8780 - val_loss: 9.0799 - val_accuracy: 0.8508\n",
      "Epoch 613/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3285 - accuracy: 0.8769 - val_loss: 9.6164 - val_accuracy: 0.8538\n",
      "Epoch 614/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9307 - accuracy: 0.8792 - val_loss: 9.7456 - val_accuracy: 0.8434\n",
      "Epoch 615/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1510 - accuracy: 0.8780 - val_loss: 9.6879 - val_accuracy: 0.8479\n",
      "Epoch 616/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1769 - accuracy: 0.8780 - val_loss: 9.6384 - val_accuracy: 0.8508\n",
      "Epoch 617/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9582 - accuracy: 0.8799 - val_loss: 9.6897 - val_accuracy: 0.8434\n",
      "Epoch 618/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2780 - accuracy: 0.8758 - val_loss: 9.9318 - val_accuracy: 0.8508\n",
      "Epoch 619/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9658 - accuracy: 0.8817 - val_loss: 9.7153 - val_accuracy: 0.8390\n",
      "Epoch 620/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.0755 - accuracy: 0.8762 - val_loss: 9.4457 - val_accuracy: 0.8434\n",
      "Epoch 621/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 4.1213 - accuracy: 0.8792 - val_loss: 9.6229 - val_accuracy: 0.8464\n",
      "Epoch 622/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.1428 - accuracy: 0.8784 - val_loss: 9.6820 - val_accuracy: 0.8449\n",
      "Epoch 623/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.1071 - accuracy: 0.8773 - val_loss: 9.9404 - val_accuracy: 0.8375\n",
      "Epoch 624/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 4.3098 - accuracy: 0.8740 - val_loss: 10.2162 - val_accuracy: 0.8419\n",
      "Epoch 625/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0044 - accuracy: 0.8714 - val_loss: 9.5875 - val_accuracy: 0.8567\n",
      "Epoch 626/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9667 - accuracy: 0.8810 - val_loss: 9.7371 - val_accuracy: 0.8552\n",
      "Epoch 627/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0341 - accuracy: 0.8795 - val_loss: 9.1239 - val_accuracy: 0.8508\n",
      "Epoch 628/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2088 - accuracy: 0.8777 - val_loss: 9.6492 - val_accuracy: 0.8464\n",
      "Epoch 629/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1389 - accuracy: 0.8784 - val_loss: 9.4260 - val_accuracy: 0.8493\n",
      "Epoch 630/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9204 - accuracy: 0.8766 - val_loss: 9.8292 - val_accuracy: 0.8449\n",
      "Epoch 631/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.3136 - accuracy: 0.8703 - val_loss: 9.8116 - val_accuracy: 0.8479\n",
      "Epoch 632/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.3422 - accuracy: 0.8784 - val_loss: 9.4915 - val_accuracy: 0.8419\n",
      "Epoch 633/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8964 - accuracy: 0.8780 - val_loss: 9.8493 - val_accuracy: 0.8464\n",
      "Epoch 634/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9911 - accuracy: 0.8762 - val_loss: 9.4239 - val_accuracy: 0.8567\n",
      "Epoch 635/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0439 - accuracy: 0.8788 - val_loss: 9.1907 - val_accuracy: 0.8493\n",
      "Epoch 636/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8473 - accuracy: 0.8740 - val_loss: 9.6067 - val_accuracy: 0.8434\n",
      "Epoch 637/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9418 - accuracy: 0.8799 - val_loss: 9.7327 - val_accuracy: 0.8523\n",
      "Epoch 638/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.0091 - accuracy: 0.8784 - val_loss: 9.5434 - val_accuracy: 0.8493\n",
      "Epoch 639/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9546 - accuracy: 0.8777 - val_loss: 9.5929 - val_accuracy: 0.8493\n",
      "Epoch 640/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2521 - accuracy: 0.8777 - val_loss: 9.4704 - val_accuracy: 0.8567\n",
      "Epoch 641/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9365 - accuracy: 0.8817 - val_loss: 9.2953 - val_accuracy: 0.8582\n",
      "Epoch 642/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0367 - accuracy: 0.8788 - val_loss: 9.5305 - val_accuracy: 0.8493\n",
      "Epoch 643/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.2644 - accuracy: 0.8755 - val_loss: 9.1520 - val_accuracy: 0.8419\n",
      "Epoch 644/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1353 - accuracy: 0.8792 - val_loss: 9.9257 - val_accuracy: 0.8479\n",
      "Epoch 645/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1045 - accuracy: 0.8784 - val_loss: 9.3469 - val_accuracy: 0.8567\n",
      "Epoch 646/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.1636 - accuracy: 0.8766 - val_loss: 9.8222 - val_accuracy: 0.8479\n",
      "Epoch 647/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1962 - accuracy: 0.8773 - val_loss: 9.7262 - val_accuracy: 0.8479\n",
      "Epoch 648/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9486 - accuracy: 0.8744 - val_loss: 9.6078 - val_accuracy: 0.8523\n",
      "Epoch 649/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0758 - accuracy: 0.8843 - val_loss: 9.7042 - val_accuracy: 0.8538\n",
      "Epoch 650/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8654 - accuracy: 0.8747 - val_loss: 9.2082 - val_accuracy: 0.8508\n",
      "Epoch 651/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9641 - accuracy: 0.8777 - val_loss: 9.3559 - val_accuracy: 0.8523\n",
      "Epoch 652/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.1292 - accuracy: 0.8762 - val_loss: 9.2246 - val_accuracy: 0.8597\n",
      "Epoch 653/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.0807 - accuracy: 0.8773 - val_loss: 9.7028 - val_accuracy: 0.8434\n",
      "Epoch 654/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0502 - accuracy: 0.8788 - val_loss: 9.3512 - val_accuracy: 0.8449\n",
      "Epoch 655/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9993 - accuracy: 0.8773 - val_loss: 9.3246 - val_accuracy: 0.8479\n",
      "Epoch 656/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8824 - accuracy: 0.8777 - val_loss: 9.5755 - val_accuracy: 0.8508\n",
      "Epoch 657/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9972 - accuracy: 0.8762 - val_loss: 9.0577 - val_accuracy: 0.8464\n",
      "Epoch 658/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8940 - accuracy: 0.8773 - val_loss: 9.5288 - val_accuracy: 0.8464\n",
      "Epoch 659/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8432 - accuracy: 0.8799 - val_loss: 9.1205 - val_accuracy: 0.8523\n",
      "Epoch 660/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8686 - accuracy: 0.8777 - val_loss: 9.3560 - val_accuracy: 0.8508\n",
      "Epoch 661/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8162 - accuracy: 0.8829 - val_loss: 9.3647 - val_accuracy: 0.8508\n",
      "Epoch 662/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9781 - accuracy: 0.8758 - val_loss: 9.3848 - val_accuracy: 0.8567\n",
      "Epoch 663/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8932 - accuracy: 0.8755 - val_loss: 9.7140 - val_accuracy: 0.8523\n",
      "Epoch 664/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9124 - accuracy: 0.8777 - val_loss: 9.7303 - val_accuracy: 0.8449\n",
      "Epoch 665/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9786 - accuracy: 0.8784 - val_loss: 9.5567 - val_accuracy: 0.8508\n",
      "Epoch 666/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9607 - accuracy: 0.8751 - val_loss: 9.4363 - val_accuracy: 0.8567\n",
      "Epoch 667/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0329 - accuracy: 0.8784 - val_loss: 9.3480 - val_accuracy: 0.8508\n",
      "Epoch 668/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9787 - accuracy: 0.8736 - val_loss: 9.2047 - val_accuracy: 0.8508\n",
      "Epoch 669/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.0929 - accuracy: 0.8784 - val_loss: 9.8172 - val_accuracy: 0.8567\n",
      "Epoch 670/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0859 - accuracy: 0.8769 - val_loss: 9.4457 - val_accuracy: 0.8597\n",
      "Epoch 671/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6768 - accuracy: 0.8825 - val_loss: 9.3962 - val_accuracy: 0.8538\n",
      "Epoch 672/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7760 - accuracy: 0.8762 - val_loss: 9.7392 - val_accuracy: 0.8567\n",
      "Epoch 673/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8485 - accuracy: 0.8755 - val_loss: 9.6596 - val_accuracy: 0.8375\n",
      "Epoch 674/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.1239 - accuracy: 0.8777 - val_loss: 9.6619 - val_accuracy: 0.8449\n",
      "Epoch 675/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9128 - accuracy: 0.8769 - val_loss: 9.9998 - val_accuracy: 0.8449\n",
      "Epoch 676/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0879 - accuracy: 0.8740 - val_loss: 9.2084 - val_accuracy: 0.8612\n",
      "Epoch 677/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9111 - accuracy: 0.8795 - val_loss: 9.7012 - val_accuracy: 0.8538\n",
      "Epoch 678/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.2599 - accuracy: 0.8744 - val_loss: 9.5665 - val_accuracy: 0.8331\n",
      "Epoch 679/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7661 - accuracy: 0.8799 - val_loss: 9.1238 - val_accuracy: 0.8493\n",
      "Epoch 680/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7768 - accuracy: 0.8806 - val_loss: 9.0033 - val_accuracy: 0.8434\n",
      "Epoch 681/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 4.0629 - accuracy: 0.8773 - val_loss: 9.3789 - val_accuracy: 0.8464\n",
      "Epoch 682/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9586 - accuracy: 0.8777 - val_loss: 8.9484 - val_accuracy: 0.8567\n",
      "Epoch 683/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8015 - accuracy: 0.8777 - val_loss: 9.0354 - val_accuracy: 0.8493\n",
      "Epoch 684/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8665 - accuracy: 0.8740 - val_loss: 9.4785 - val_accuracy: 0.8405\n",
      "Epoch 685/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8652 - accuracy: 0.8806 - val_loss: 9.3700 - val_accuracy: 0.8464\n",
      "Epoch 686/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8743 - accuracy: 0.8729 - val_loss: 9.5649 - val_accuracy: 0.8405\n",
      "Epoch 687/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8525 - accuracy: 0.8806 - val_loss: 8.9359 - val_accuracy: 0.8493\n",
      "Epoch 688/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8041 - accuracy: 0.8784 - val_loss: 8.8710 - val_accuracy: 0.8567\n",
      "Epoch 689/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9238 - accuracy: 0.8769 - val_loss: 9.0031 - val_accuracy: 0.8493\n",
      "Epoch 690/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7342 - accuracy: 0.8784 - val_loss: 8.6711 - val_accuracy: 0.8582\n",
      "Epoch 691/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8715 - accuracy: 0.8740 - val_loss: 9.4882 - val_accuracy: 0.8523\n",
      "Epoch 692/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8388 - accuracy: 0.8825 - val_loss: 9.4861 - val_accuracy: 0.8538\n",
      "Epoch 693/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9915 - accuracy: 0.8762 - val_loss: 9.1980 - val_accuracy: 0.8508\n",
      "Epoch 694/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8360 - accuracy: 0.8744 - val_loss: 9.7325 - val_accuracy: 0.8552\n",
      "Epoch 695/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7642 - accuracy: 0.8747 - val_loss: 9.5434 - val_accuracy: 0.8493\n",
      "Epoch 696/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9270 - accuracy: 0.8758 - val_loss: 9.3971 - val_accuracy: 0.8508\n",
      "Epoch 697/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8253 - accuracy: 0.8788 - val_loss: 9.9497 - val_accuracy: 0.8464\n",
      "Epoch 698/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8740 - accuracy: 0.8788 - val_loss: 9.4910 - val_accuracy: 0.8419\n",
      "Epoch 699/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8754 - accuracy: 0.8769 - val_loss: 9.1323 - val_accuracy: 0.8479\n",
      "Epoch 700/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8601 - accuracy: 0.8777 - val_loss: 9.3879 - val_accuracy: 0.8419\n",
      "Epoch 701/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9093 - accuracy: 0.8773 - val_loss: 8.9706 - val_accuracy: 0.8493\n",
      "Epoch 702/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.1596 - accuracy: 0.8773 - val_loss: 8.9786 - val_accuracy: 0.8479\n",
      "Epoch 703/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8786 - accuracy: 0.8718 - val_loss: 9.3326 - val_accuracy: 0.8493\n",
      "Epoch 704/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6852 - accuracy: 0.8814 - val_loss: 9.3881 - val_accuracy: 0.8405\n",
      "Epoch 705/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7553 - accuracy: 0.8744 - val_loss: 9.0576 - val_accuracy: 0.8449\n",
      "Epoch 706/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9801 - accuracy: 0.8744 - val_loss: 9.4602 - val_accuracy: 0.8479\n",
      "Epoch 707/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9480 - accuracy: 0.8777 - val_loss: 9.4576 - val_accuracy: 0.8405\n",
      "Epoch 708/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8020 - accuracy: 0.8766 - val_loss: 8.9324 - val_accuracy: 0.8523\n",
      "Epoch 709/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7648 - accuracy: 0.8784 - val_loss: 8.9355 - val_accuracy: 0.8405\n",
      "Epoch 710/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7018 - accuracy: 0.8799 - val_loss: 8.8722 - val_accuracy: 0.8493\n",
      "Epoch 711/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8641 - accuracy: 0.8755 - val_loss: 9.4273 - val_accuracy: 0.8405\n",
      "Epoch 712/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8833 - accuracy: 0.8747 - val_loss: 8.9703 - val_accuracy: 0.8597\n",
      "Epoch 713/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9511 - accuracy: 0.8780 - val_loss: 9.3684 - val_accuracy: 0.8493\n",
      "Epoch 714/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9295 - accuracy: 0.8755 - val_loss: 10.1475 - val_accuracy: 0.8419\n",
      "Epoch 715/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0759 - accuracy: 0.8799 - val_loss: 9.3764 - val_accuracy: 0.8419\n",
      "Epoch 716/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8074 - accuracy: 0.8777 - val_loss: 9.0698 - val_accuracy: 0.8479\n",
      "Epoch 717/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8104 - accuracy: 0.8792 - val_loss: 8.8973 - val_accuracy: 0.8464\n",
      "Epoch 718/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7281 - accuracy: 0.8721 - val_loss: 8.9176 - val_accuracy: 0.8508\n",
      "Epoch 719/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7252 - accuracy: 0.8806 - val_loss: 9.4382 - val_accuracy: 0.8464\n",
      "Epoch 720/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6668 - accuracy: 0.8777 - val_loss: 8.9654 - val_accuracy: 0.8523\n",
      "Epoch 721/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7787 - accuracy: 0.8825 - val_loss: 8.8281 - val_accuracy: 0.8464\n",
      "Epoch 722/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7924 - accuracy: 0.8799 - val_loss: 9.1533 - val_accuracy: 0.8419\n",
      "Epoch 723/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9348 - accuracy: 0.8777 - val_loss: 9.2838 - val_accuracy: 0.8449\n",
      "Epoch 724/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 4.0286 - accuracy: 0.8792 - val_loss: 8.9411 - val_accuracy: 0.8493\n",
      "Epoch 725/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6564 - accuracy: 0.8766 - val_loss: 9.5500 - val_accuracy: 0.8493\n",
      "Epoch 726/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9396 - accuracy: 0.8777 - val_loss: 8.9139 - val_accuracy: 0.8479\n",
      "Epoch 727/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7993 - accuracy: 0.8788 - val_loss: 8.8314 - val_accuracy: 0.8508\n",
      "Epoch 728/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8209 - accuracy: 0.8762 - val_loss: 9.1916 - val_accuracy: 0.8479\n",
      "Epoch 729/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8398 - accuracy: 0.8755 - val_loss: 9.2672 - val_accuracy: 0.8434\n",
      "Epoch 730/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8808 - accuracy: 0.8814 - val_loss: 8.9779 - val_accuracy: 0.8582\n",
      "Epoch 731/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7574 - accuracy: 0.8773 - val_loss: 8.9795 - val_accuracy: 0.8434\n",
      "Epoch 732/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6850 - accuracy: 0.8769 - val_loss: 9.0349 - val_accuracy: 0.8464\n",
      "Epoch 733/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7743 - accuracy: 0.8803 - val_loss: 8.7469 - val_accuracy: 0.8405\n",
      "Epoch 734/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7988 - accuracy: 0.8755 - val_loss: 9.0478 - val_accuracy: 0.8449\n",
      "Epoch 735/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6648 - accuracy: 0.8744 - val_loss: 8.9014 - val_accuracy: 0.8390\n",
      "Epoch 736/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7116 - accuracy: 0.8755 - val_loss: 8.8640 - val_accuracy: 0.8419\n",
      "Epoch 737/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6832 - accuracy: 0.8817 - val_loss: 8.7421 - val_accuracy: 0.8434\n",
      "Epoch 738/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6465 - accuracy: 0.8792 - val_loss: 9.0169 - val_accuracy: 0.8449\n",
      "Epoch 739/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7159 - accuracy: 0.8806 - val_loss: 8.8139 - val_accuracy: 0.8434\n",
      "Epoch 740/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5540 - accuracy: 0.8780 - val_loss: 9.1601 - val_accuracy: 0.8405\n",
      "Epoch 741/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7745 - accuracy: 0.8784 - val_loss: 8.7626 - val_accuracy: 0.8464\n",
      "Epoch 742/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8427 - accuracy: 0.8780 - val_loss: 9.2311 - val_accuracy: 0.8390\n",
      "Epoch 743/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6848 - accuracy: 0.8766 - val_loss: 8.8920 - val_accuracy: 0.8538\n",
      "Epoch 744/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6198 - accuracy: 0.8751 - val_loss: 8.7368 - val_accuracy: 0.8434\n",
      "Epoch 745/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9301 - accuracy: 0.8777 - val_loss: 8.8657 - val_accuracy: 0.8493\n",
      "Epoch 746/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7581 - accuracy: 0.8814 - val_loss: 8.8517 - val_accuracy: 0.8449\n",
      "Epoch 747/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6614 - accuracy: 0.8762 - val_loss: 8.6156 - val_accuracy: 0.8523\n",
      "Epoch 748/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5253 - accuracy: 0.8806 - val_loss: 9.1220 - val_accuracy: 0.8523\n",
      "Epoch 749/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8786 - accuracy: 0.8769 - val_loss: 9.0209 - val_accuracy: 0.8552\n",
      "Epoch 750/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8660 - accuracy: 0.8780 - val_loss: 8.7239 - val_accuracy: 0.8493\n",
      "Epoch 751/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7665 - accuracy: 0.8806 - val_loss: 8.7144 - val_accuracy: 0.8523\n",
      "Epoch 752/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5830 - accuracy: 0.8795 - val_loss: 8.6465 - val_accuracy: 0.8508\n",
      "Epoch 753/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5147 - accuracy: 0.8766 - val_loss: 8.8735 - val_accuracy: 0.8419\n",
      "Epoch 754/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7410 - accuracy: 0.8780 - val_loss: 8.9217 - val_accuracy: 0.8508\n",
      "Epoch 755/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9111 - accuracy: 0.8792 - val_loss: 8.4769 - val_accuracy: 0.8508\n",
      "Epoch 756/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9367 - accuracy: 0.8784 - val_loss: 8.5403 - val_accuracy: 0.8538\n",
      "Epoch 757/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7043 - accuracy: 0.8799 - val_loss: 8.6197 - val_accuracy: 0.8508\n",
      "Epoch 758/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7643 - accuracy: 0.8803 - val_loss: 8.6634 - val_accuracy: 0.8493\n",
      "Epoch 759/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7696 - accuracy: 0.8780 - val_loss: 8.5134 - val_accuracy: 0.8493\n",
      "Epoch 760/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8762 - accuracy: 0.8799 - val_loss: 8.3465 - val_accuracy: 0.8493\n",
      "Epoch 761/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6867 - accuracy: 0.8814 - val_loss: 8.7932 - val_accuracy: 0.8538\n",
      "Epoch 762/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8018 - accuracy: 0.8766 - val_loss: 8.7174 - val_accuracy: 0.8464\n",
      "Epoch 763/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7813 - accuracy: 0.8769 - val_loss: 8.7247 - val_accuracy: 0.8464\n",
      "Epoch 764/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6196 - accuracy: 0.8780 - val_loss: 8.6070 - val_accuracy: 0.8493\n",
      "Epoch 765/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9362 - accuracy: 0.8795 - val_loss: 8.5470 - val_accuracy: 0.8508\n",
      "Epoch 766/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8616 - accuracy: 0.8810 - val_loss: 8.7425 - val_accuracy: 0.8449\n",
      "Epoch 767/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8470 - accuracy: 0.8817 - val_loss: 8.7197 - val_accuracy: 0.8538\n",
      "Epoch 768/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7033 - accuracy: 0.8777 - val_loss: 8.3751 - val_accuracy: 0.8538\n",
      "Epoch 769/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5727 - accuracy: 0.8799 - val_loss: 8.6054 - val_accuracy: 0.8552\n",
      "Epoch 770/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.9457 - accuracy: 0.8773 - val_loss: 8.7428 - val_accuracy: 0.8538\n",
      "Epoch 771/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8818 - accuracy: 0.8803 - val_loss: 8.7519 - val_accuracy: 0.8449\n",
      "Epoch 772/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8538 - accuracy: 0.8773 - val_loss: 8.6610 - val_accuracy: 0.8582\n",
      "Epoch 773/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.8364 - accuracy: 0.8755 - val_loss: 8.7714 - val_accuracy: 0.8538\n",
      "Epoch 774/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7743 - accuracy: 0.8810 - val_loss: 8.2641 - val_accuracy: 0.8538\n",
      "Epoch 775/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5152 - accuracy: 0.8817 - val_loss: 8.8822 - val_accuracy: 0.8567\n",
      "Epoch 776/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7310 - accuracy: 0.8840 - val_loss: 9.0250 - val_accuracy: 0.8597\n",
      "Epoch 777/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8327 - accuracy: 0.8751 - val_loss: 8.5227 - val_accuracy: 0.8523\n",
      "Epoch 778/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6447 - accuracy: 0.8825 - val_loss: 8.4110 - val_accuracy: 0.8552\n",
      "Epoch 779/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6734 - accuracy: 0.8810 - val_loss: 8.6409 - val_accuracy: 0.8449\n",
      "Epoch 780/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5044 - accuracy: 0.8780 - val_loss: 8.7963 - val_accuracy: 0.8434\n",
      "Epoch 781/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7290 - accuracy: 0.8803 - val_loss: 8.5206 - val_accuracy: 0.8508\n",
      "Epoch 782/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6459 - accuracy: 0.8755 - val_loss: 8.5789 - val_accuracy: 0.8493\n",
      "Epoch 783/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7403 - accuracy: 0.8714 - val_loss: 9.0002 - val_accuracy: 0.8538\n",
      "Epoch 784/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6965 - accuracy: 0.8766 - val_loss: 8.7184 - val_accuracy: 0.8508\n",
      "Epoch 785/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8155 - accuracy: 0.8792 - val_loss: 9.0039 - val_accuracy: 0.8346\n",
      "Epoch 786/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7635 - accuracy: 0.8762 - val_loss: 8.6101 - val_accuracy: 0.8464\n",
      "Epoch 787/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6069 - accuracy: 0.8810 - val_loss: 8.5099 - val_accuracy: 0.8464\n",
      "Epoch 788/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5200 - accuracy: 0.8758 - val_loss: 8.4781 - val_accuracy: 0.8493\n",
      "Epoch 789/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6346 - accuracy: 0.8784 - val_loss: 8.9437 - val_accuracy: 0.8434\n",
      "Epoch 790/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8992 - accuracy: 0.8766 - val_loss: 8.6848 - val_accuracy: 0.8508\n",
      "Epoch 791/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5529 - accuracy: 0.8814 - val_loss: 8.3984 - val_accuracy: 0.8508\n",
      "Epoch 792/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7014 - accuracy: 0.8769 - val_loss: 8.8316 - val_accuracy: 0.8479\n",
      "Epoch 793/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5270 - accuracy: 0.8803 - val_loss: 8.7944 - val_accuracy: 0.8449\n",
      "Epoch 794/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7187 - accuracy: 0.8773 - val_loss: 8.8519 - val_accuracy: 0.8464\n",
      "Epoch 795/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7424 - accuracy: 0.8806 - val_loss: 8.9388 - val_accuracy: 0.8493\n",
      "Epoch 796/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6617 - accuracy: 0.8773 - val_loss: 8.6277 - val_accuracy: 0.8464\n",
      "Epoch 797/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6733 - accuracy: 0.8777 - val_loss: 8.3878 - val_accuracy: 0.8508\n",
      "Epoch 798/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7561 - accuracy: 0.8829 - val_loss: 8.2085 - val_accuracy: 0.8552\n",
      "Epoch 799/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5956 - accuracy: 0.8806 - val_loss: 8.8201 - val_accuracy: 0.8479\n",
      "Epoch 800/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.9226 - accuracy: 0.8784 - val_loss: 8.8242 - val_accuracy: 0.8538\n",
      "Epoch 801/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4650 - accuracy: 0.8758 - val_loss: 8.6323 - val_accuracy: 0.8567\n",
      "Epoch 802/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7722 - accuracy: 0.8799 - val_loss: 8.3687 - val_accuracy: 0.8479\n",
      "Epoch 803/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6285 - accuracy: 0.8825 - val_loss: 8.6702 - val_accuracy: 0.8479\n",
      "Epoch 804/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6251 - accuracy: 0.8769 - val_loss: 8.8392 - val_accuracy: 0.8479\n",
      "Epoch 805/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6141 - accuracy: 0.8780 - val_loss: 8.5154 - val_accuracy: 0.8567\n",
      "Epoch 806/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5495 - accuracy: 0.8758 - val_loss: 8.5911 - val_accuracy: 0.8479\n",
      "Epoch 807/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5058 - accuracy: 0.8795 - val_loss: 8.3759 - val_accuracy: 0.8523\n",
      "Epoch 808/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6869 - accuracy: 0.8806 - val_loss: 8.3594 - val_accuracy: 0.8523\n",
      "Epoch 809/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7077 - accuracy: 0.8851 - val_loss: 8.5042 - val_accuracy: 0.8523\n",
      "Epoch 810/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5689 - accuracy: 0.8788 - val_loss: 8.3942 - val_accuracy: 0.8493\n",
      "Epoch 811/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6762 - accuracy: 0.8792 - val_loss: 8.1437 - val_accuracy: 0.8479\n",
      "Epoch 812/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6919 - accuracy: 0.8814 - val_loss: 8.9326 - val_accuracy: 0.8479\n",
      "Epoch 813/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5825 - accuracy: 0.8792 - val_loss: 8.2788 - val_accuracy: 0.8508\n",
      "Epoch 814/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6312 - accuracy: 0.8777 - val_loss: 8.4730 - val_accuracy: 0.8523\n",
      "Epoch 815/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5757 - accuracy: 0.8803 - val_loss: 8.6375 - val_accuracy: 0.8449\n",
      "Epoch 816/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6716 - accuracy: 0.8777 - val_loss: 8.3144 - val_accuracy: 0.8538\n",
      "Epoch 817/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6114 - accuracy: 0.8821 - val_loss: 8.6433 - val_accuracy: 0.8449\n",
      "Epoch 818/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7562 - accuracy: 0.8832 - val_loss: 8.3472 - val_accuracy: 0.8449\n",
      "Epoch 819/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6031 - accuracy: 0.8755 - val_loss: 8.6160 - val_accuracy: 0.8434\n",
      "Epoch 820/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5718 - accuracy: 0.8799 - val_loss: 8.2150 - val_accuracy: 0.8538\n",
      "Epoch 821/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4670 - accuracy: 0.8829 - val_loss: 8.6981 - val_accuracy: 0.8479\n",
      "Epoch 822/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7946 - accuracy: 0.8762 - val_loss: 8.9413 - val_accuracy: 0.8464\n",
      "Epoch 823/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6337 - accuracy: 0.8773 - val_loss: 8.3236 - val_accuracy: 0.8552\n",
      "Epoch 824/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6073 - accuracy: 0.8795 - val_loss: 8.0901 - val_accuracy: 0.8641\n",
      "Epoch 825/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5417 - accuracy: 0.8829 - val_loss: 8.1541 - val_accuracy: 0.8523\n",
      "Epoch 826/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5107 - accuracy: 0.8814 - val_loss: 8.7289 - val_accuracy: 0.8434\n",
      "Epoch 827/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4730 - accuracy: 0.8792 - val_loss: 8.5490 - val_accuracy: 0.8479\n",
      "Epoch 828/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5727 - accuracy: 0.8840 - val_loss: 8.7608 - val_accuracy: 0.8567\n",
      "Epoch 829/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5309 - accuracy: 0.8788 - val_loss: 8.3267 - val_accuracy: 0.8552\n",
      "Epoch 830/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5901 - accuracy: 0.8817 - val_loss: 8.5134 - val_accuracy: 0.8508\n",
      "Epoch 831/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7102 - accuracy: 0.8762 - val_loss: 8.3238 - val_accuracy: 0.8508\n",
      "Epoch 832/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6057 - accuracy: 0.8773 - val_loss: 8.5265 - val_accuracy: 0.8552\n",
      "Epoch 833/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5698 - accuracy: 0.8788 - val_loss: 8.3945 - val_accuracy: 0.8508\n",
      "Epoch 834/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3994 - accuracy: 0.8751 - val_loss: 8.9433 - val_accuracy: 0.8479\n",
      "Epoch 835/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7266 - accuracy: 0.8773 - val_loss: 8.2151 - val_accuracy: 0.8523\n",
      "Epoch 836/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7083 - accuracy: 0.8832 - val_loss: 8.3486 - val_accuracy: 0.8479\n",
      "Epoch 837/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3983 - accuracy: 0.8806 - val_loss: 8.4245 - val_accuracy: 0.8493\n",
      "Epoch 838/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4453 - accuracy: 0.8810 - val_loss: 8.3171 - val_accuracy: 0.8464\n",
      "Epoch 839/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5628 - accuracy: 0.8773 - val_loss: 8.4193 - val_accuracy: 0.8493\n",
      "Epoch 840/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5707 - accuracy: 0.8780 - val_loss: 8.8318 - val_accuracy: 0.8567\n",
      "Epoch 841/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6239 - accuracy: 0.8784 - val_loss: 8.6870 - val_accuracy: 0.8523\n",
      "Epoch 842/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7066 - accuracy: 0.8799 - val_loss: 8.8334 - val_accuracy: 0.8479\n",
      "Epoch 843/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5894 - accuracy: 0.8814 - val_loss: 8.5300 - val_accuracy: 0.8523\n",
      "Epoch 844/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5797 - accuracy: 0.8773 - val_loss: 8.6831 - val_accuracy: 0.8538\n",
      "Epoch 845/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4664 - accuracy: 0.8806 - val_loss: 8.5666 - val_accuracy: 0.8375\n",
      "Epoch 846/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7603 - accuracy: 0.8788 - val_loss: 8.8167 - val_accuracy: 0.8523\n",
      "Epoch 847/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6372 - accuracy: 0.8788 - val_loss: 8.5241 - val_accuracy: 0.8493\n",
      "Epoch 848/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5902 - accuracy: 0.8784 - val_loss: 8.4214 - val_accuracy: 0.8552\n",
      "Epoch 849/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4988 - accuracy: 0.8829 - val_loss: 9.2559 - val_accuracy: 0.8523\n",
      "Epoch 850/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7154 - accuracy: 0.8788 - val_loss: 8.6118 - val_accuracy: 0.8493\n",
      "Epoch 851/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5447 - accuracy: 0.8795 - val_loss: 8.3157 - val_accuracy: 0.8523\n",
      "Epoch 852/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5100 - accuracy: 0.8814 - val_loss: 8.8240 - val_accuracy: 0.8523\n",
      "Epoch 853/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4934 - accuracy: 0.8780 - val_loss: 8.7072 - val_accuracy: 0.8493\n",
      "Epoch 854/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4447 - accuracy: 0.8847 - val_loss: 8.4325 - val_accuracy: 0.8493\n",
      "Epoch 855/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5554 - accuracy: 0.8803 - val_loss: 8.9926 - val_accuracy: 0.8419\n",
      "Epoch 856/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5347 - accuracy: 0.8780 - val_loss: 8.4618 - val_accuracy: 0.8582\n",
      "Epoch 857/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5472 - accuracy: 0.8773 - val_loss: 8.8150 - val_accuracy: 0.8538\n",
      "Epoch 858/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4077 - accuracy: 0.8817 - val_loss: 8.5088 - val_accuracy: 0.8464\n",
      "Epoch 859/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4674 - accuracy: 0.8825 - val_loss: 8.2575 - val_accuracy: 0.8434\n",
      "Epoch 860/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3840 - accuracy: 0.8780 - val_loss: 8.1768 - val_accuracy: 0.8552\n",
      "Epoch 861/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3347 - accuracy: 0.8810 - val_loss: 8.3074 - val_accuracy: 0.8479\n",
      "Epoch 862/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5138 - accuracy: 0.8817 - val_loss: 8.4077 - val_accuracy: 0.8538\n",
      "Epoch 863/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4672 - accuracy: 0.8865 - val_loss: 8.5379 - val_accuracy: 0.8479\n",
      "Epoch 864/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4991 - accuracy: 0.8773 - val_loss: 8.5605 - val_accuracy: 0.8523\n",
      "Epoch 865/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4854 - accuracy: 0.8851 - val_loss: 8.2447 - val_accuracy: 0.8479\n",
      "Epoch 866/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6329 - accuracy: 0.8792 - val_loss: 8.3564 - val_accuracy: 0.8552\n",
      "Epoch 867/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3555 - accuracy: 0.8843 - val_loss: 8.2653 - val_accuracy: 0.8552\n",
      "Epoch 868/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6120 - accuracy: 0.8784 - val_loss: 8.4686 - val_accuracy: 0.8449\n",
      "Epoch 869/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4381 - accuracy: 0.8792 - val_loss: 8.3706 - val_accuracy: 0.8567\n",
      "Epoch 870/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3795 - accuracy: 0.8799 - val_loss: 8.4816 - val_accuracy: 0.8493\n",
      "Epoch 871/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6378 - accuracy: 0.8829 - val_loss: 8.4617 - val_accuracy: 0.8538\n",
      "Epoch 872/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3436 - accuracy: 0.8810 - val_loss: 8.6381 - val_accuracy: 0.8390\n",
      "Epoch 873/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.8171 - accuracy: 0.8814 - val_loss: 8.6076 - val_accuracy: 0.8493\n",
      "Epoch 874/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.7908 - accuracy: 0.8792 - val_loss: 8.1243 - val_accuracy: 0.8567\n",
      "Epoch 875/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5059 - accuracy: 0.8780 - val_loss: 8.5924 - val_accuracy: 0.8493\n",
      "Epoch 876/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5221 - accuracy: 0.8806 - val_loss: 8.3810 - val_accuracy: 0.8523\n",
      "Epoch 877/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4832 - accuracy: 0.8788 - val_loss: 8.6891 - val_accuracy: 0.8493\n",
      "Epoch 878/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5327 - accuracy: 0.8784 - val_loss: 8.4875 - val_accuracy: 0.8523\n",
      "Epoch 879/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6154 - accuracy: 0.8788 - val_loss: 8.0769 - val_accuracy: 0.8523\n",
      "Epoch 880/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4372 - accuracy: 0.8817 - val_loss: 8.1951 - val_accuracy: 0.8479\n",
      "Epoch 881/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5329 - accuracy: 0.8769 - val_loss: 8.6273 - val_accuracy: 0.8449\n",
      "Epoch 882/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5472 - accuracy: 0.8747 - val_loss: 8.4551 - val_accuracy: 0.8597\n",
      "Epoch 883/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3859 - accuracy: 0.8817 - val_loss: 8.0342 - val_accuracy: 0.8449\n",
      "Epoch 884/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4238 - accuracy: 0.8810 - val_loss: 8.4338 - val_accuracy: 0.8493\n",
      "Epoch 885/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4030 - accuracy: 0.8814 - val_loss: 8.0644 - val_accuracy: 0.8493\n",
      "Epoch 886/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3065 - accuracy: 0.8836 - val_loss: 8.3727 - val_accuracy: 0.8479\n",
      "Epoch 887/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3136 - accuracy: 0.8814 - val_loss: 8.3079 - val_accuracy: 0.8523\n",
      "Epoch 888/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4083 - accuracy: 0.8810 - val_loss: 8.3205 - val_accuracy: 0.8567\n",
      "Epoch 889/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4153 - accuracy: 0.8832 - val_loss: 8.7751 - val_accuracy: 0.8479\n",
      "Epoch 890/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5072 - accuracy: 0.8799 - val_loss: 8.1113 - val_accuracy: 0.8612\n",
      "Epoch 891/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3527 - accuracy: 0.8821 - val_loss: 8.5498 - val_accuracy: 0.8552\n",
      "Epoch 892/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4562 - accuracy: 0.8788 - val_loss: 8.2204 - val_accuracy: 0.8597\n",
      "Epoch 893/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5572 - accuracy: 0.8747 - val_loss: 8.1101 - val_accuracy: 0.8597\n",
      "Epoch 894/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4265 - accuracy: 0.8817 - val_loss: 7.9881 - val_accuracy: 0.8656\n",
      "Epoch 895/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6037 - accuracy: 0.8806 - val_loss: 8.6744 - val_accuracy: 0.8597\n",
      "Epoch 896/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.6266 - accuracy: 0.8817 - val_loss: 8.5478 - val_accuracy: 0.8523\n",
      "Epoch 897/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5978 - accuracy: 0.8773 - val_loss: 7.8019 - val_accuracy: 0.8552\n",
      "Epoch 898/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.2241 - accuracy: 0.8806 - val_loss: 7.8439 - val_accuracy: 0.8523\n",
      "Epoch 899/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3786 - accuracy: 0.8825 - val_loss: 7.9947 - val_accuracy: 0.8582\n",
      "Epoch 900/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3511 - accuracy: 0.8832 - val_loss: 8.2567 - val_accuracy: 0.8612\n",
      "Epoch 901/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5187 - accuracy: 0.8825 - val_loss: 8.2241 - val_accuracy: 0.8641\n",
      "Epoch 902/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4727 - accuracy: 0.8803 - val_loss: 8.0200 - val_accuracy: 0.8656\n",
      "Epoch 903/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6192 - accuracy: 0.8803 - val_loss: 8.6831 - val_accuracy: 0.8552\n",
      "Epoch 904/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3101 - accuracy: 0.8817 - val_loss: 8.6855 - val_accuracy: 0.8582\n",
      "Epoch 905/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4776 - accuracy: 0.8799 - val_loss: 8.3479 - val_accuracy: 0.8552\n",
      "Epoch 906/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4075 - accuracy: 0.8840 - val_loss: 8.0071 - val_accuracy: 0.8552\n",
      "Epoch 907/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.2554 - accuracy: 0.8810 - val_loss: 8.0794 - val_accuracy: 0.8523\n",
      "Epoch 908/998\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 3.3859 - accuracy: 0.8806 - val_loss: 8.2775 - val_accuracy: 0.8508\n",
      "Epoch 909/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 3.4115 - accuracy: 0.8821 - val_loss: 8.1082 - val_accuracy: 0.8582\n",
      "Epoch 910/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.5224 - accuracy: 0.8821 - val_loss: 8.7385 - val_accuracy: 0.8464\n",
      "Epoch 911/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4241 - accuracy: 0.8810 - val_loss: 8.0643 - val_accuracy: 0.8523\n",
      "Epoch 912/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3195 - accuracy: 0.8817 - val_loss: 8.5585 - val_accuracy: 0.8523\n",
      "Epoch 913/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.2775 - accuracy: 0.8814 - val_loss: 8.2124 - val_accuracy: 0.8449\n",
      "Epoch 914/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3878 - accuracy: 0.8795 - val_loss: 8.2736 - val_accuracy: 0.8434\n",
      "Epoch 915/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4030 - accuracy: 0.8840 - val_loss: 8.3643 - val_accuracy: 0.8552\n",
      "Epoch 916/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4819 - accuracy: 0.8817 - val_loss: 8.3275 - val_accuracy: 0.8523\n",
      "Epoch 917/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4408 - accuracy: 0.8773 - val_loss: 7.9739 - val_accuracy: 0.8405\n",
      "Epoch 918/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3801 - accuracy: 0.8877 - val_loss: 8.3270 - val_accuracy: 0.8479\n",
      "Epoch 919/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5507 - accuracy: 0.8814 - val_loss: 7.9457 - val_accuracy: 0.8523\n",
      "Epoch 920/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3949 - accuracy: 0.8829 - val_loss: 8.5088 - val_accuracy: 0.8493\n",
      "Epoch 921/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4398 - accuracy: 0.8799 - val_loss: 8.6391 - val_accuracy: 0.8538\n",
      "Epoch 922/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4570 - accuracy: 0.8821 - val_loss: 7.9917 - val_accuracy: 0.8612\n",
      "Epoch 923/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3468 - accuracy: 0.8788 - val_loss: 8.5645 - val_accuracy: 0.8508\n",
      "Epoch 924/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5128 - accuracy: 0.8803 - val_loss: 8.2622 - val_accuracy: 0.8582\n",
      "Epoch 925/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5632 - accuracy: 0.8788 - val_loss: 8.1641 - val_accuracy: 0.8493\n",
      "Epoch 926/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5490 - accuracy: 0.8784 - val_loss: 8.4777 - val_accuracy: 0.8508\n",
      "Epoch 927/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3094 - accuracy: 0.8814 - val_loss: 8.0380 - val_accuracy: 0.8508\n",
      "Epoch 928/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5052 - accuracy: 0.8803 - val_loss: 8.1650 - val_accuracy: 0.8538\n",
      "Epoch 929/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5611 - accuracy: 0.8795 - val_loss: 7.8587 - val_accuracy: 0.8641\n",
      "Epoch 930/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6286 - accuracy: 0.8769 - val_loss: 8.0116 - val_accuracy: 0.8552\n",
      "Epoch 931/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4118 - accuracy: 0.8803 - val_loss: 7.9749 - val_accuracy: 0.8656\n",
      "Epoch 932/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3690 - accuracy: 0.8847 - val_loss: 7.7087 - val_accuracy: 0.8538\n",
      "Epoch 933/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3200 - accuracy: 0.8814 - val_loss: 9.0086 - val_accuracy: 0.8523\n",
      "Epoch 934/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5416 - accuracy: 0.8806 - val_loss: 8.5911 - val_accuracy: 0.8538\n",
      "Epoch 935/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5189 - accuracy: 0.8836 - val_loss: 8.2824 - val_accuracy: 0.8626\n",
      "Epoch 936/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7609 - accuracy: 0.8858 - val_loss: 8.2337 - val_accuracy: 0.8523\n",
      "Epoch 937/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4124 - accuracy: 0.8843 - val_loss: 8.2742 - val_accuracy: 0.8508\n",
      "Epoch 938/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5014 - accuracy: 0.8847 - val_loss: 7.9138 - val_accuracy: 0.8612\n",
      "Epoch 939/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3008 - accuracy: 0.8806 - val_loss: 7.9605 - val_accuracy: 0.8597\n",
      "Epoch 940/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.1984 - accuracy: 0.8829 - val_loss: 8.2747 - val_accuracy: 0.8552\n",
      "Epoch 941/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.2539 - accuracy: 0.8817 - val_loss: 7.9675 - val_accuracy: 0.8434\n",
      "Epoch 942/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3367 - accuracy: 0.8817 - val_loss: 8.0859 - val_accuracy: 0.8552\n",
      "Epoch 943/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.7103 - accuracy: 0.8803 - val_loss: 8.0428 - val_accuracy: 0.8582\n",
      "Epoch 944/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.4422 - accuracy: 0.8795 - val_loss: 8.1691 - val_accuracy: 0.8597\n",
      "Epoch 945/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4095 - accuracy: 0.8780 - val_loss: 8.3497 - val_accuracy: 0.8434\n",
      "Epoch 946/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3422 - accuracy: 0.8780 - val_loss: 7.8336 - val_accuracy: 0.8552\n",
      "Epoch 947/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5605 - accuracy: 0.8810 - val_loss: 8.0612 - val_accuracy: 0.8493\n",
      "Epoch 948/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4387 - accuracy: 0.8821 - val_loss: 8.0314 - val_accuracy: 0.8464\n",
      "Epoch 949/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3602 - accuracy: 0.8840 - val_loss: 8.2550 - val_accuracy: 0.8612\n",
      "Epoch 950/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3822 - accuracy: 0.8814 - val_loss: 7.9247 - val_accuracy: 0.8449\n",
      "Epoch 951/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5343 - accuracy: 0.8825 - val_loss: 8.1254 - val_accuracy: 0.8582\n",
      "Epoch 952/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3477 - accuracy: 0.8814 - val_loss: 8.4561 - val_accuracy: 0.8567\n",
      "Epoch 953/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3575 - accuracy: 0.8836 - val_loss: 8.0108 - val_accuracy: 0.8464\n",
      "Epoch 954/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.2840 - accuracy: 0.8832 - val_loss: 8.0165 - val_accuracy: 0.8508\n",
      "Epoch 955/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.4313 - accuracy: 0.8784 - val_loss: 8.3608 - val_accuracy: 0.8612\n",
      "Epoch 956/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.2958 - accuracy: 0.8788 - val_loss: 7.8221 - val_accuracy: 0.8538\n",
      "Epoch 957/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.2046 - accuracy: 0.8825 - val_loss: 8.0081 - val_accuracy: 0.8597\n",
      "Epoch 958/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3071 - accuracy: 0.8832 - val_loss: 8.3088 - val_accuracy: 0.8552\n",
      "Epoch 959/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.4921 - accuracy: 0.8795 - val_loss: 8.4877 - val_accuracy: 0.8479\n",
      "Epoch 960/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.4058 - accuracy: 0.8843 - val_loss: 8.2725 - val_accuracy: 0.8419\n",
      "Epoch 961/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3740 - accuracy: 0.8780 - val_loss: 8.1229 - val_accuracy: 0.8538\n",
      "Epoch 962/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3092 - accuracy: 0.8829 - val_loss: 8.2358 - val_accuracy: 0.8538\n",
      "Epoch 963/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3261 - accuracy: 0.8832 - val_loss: 8.0532 - val_accuracy: 0.8552\n",
      "Epoch 964/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3116 - accuracy: 0.8810 - val_loss: 8.3314 - val_accuracy: 0.8612\n",
      "Epoch 965/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3153 - accuracy: 0.8869 - val_loss: 8.3563 - val_accuracy: 0.8582\n",
      "Epoch 966/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.5168 - accuracy: 0.8836 - val_loss: 8.6250 - val_accuracy: 0.8523\n",
      "Epoch 967/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.4781 - accuracy: 0.8829 - val_loss: 8.2532 - val_accuracy: 0.8449\n",
      "Epoch 968/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.3085 - accuracy: 0.8773 - val_loss: 8.5528 - val_accuracy: 0.8508\n",
      "Epoch 969/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.6316 - accuracy: 0.8825 - val_loss: 8.4079 - val_accuracy: 0.8552\n",
      "Epoch 970/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3623 - accuracy: 0.8806 - val_loss: 8.3448 - val_accuracy: 0.8449\n",
      "Epoch 971/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.5262 - accuracy: 0.8795 - val_loss: 8.1565 - val_accuracy: 0.8582\n",
      "Epoch 972/998\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 3.2811 - accuracy: 0.8777 - val_loss: 8.4321 - val_accuracy: 0.8582\n",
      "Epoch 973/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 3.5030 - accuracy: 0.8829 - val_loss: 8.9372 - val_accuracy: 0.8538\n",
      "Epoch 974/998\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 3.5340 - accuracy: 0.8854 - val_loss: 8.5411 - val_accuracy: 0.8508\n",
      "Epoch 975/998\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 3.4374 - accuracy: 0.8814 - val_loss: 8.2693 - val_accuracy: 0.8508\n",
      "Epoch 976/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 3.3604 - accuracy: 0.8840 - val_loss: 7.9486 - val_accuracy: 0.8582\n",
      "Epoch 977/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 3.4872 - accuracy: 0.8806 - val_loss: 8.2444 - val_accuracy: 0.8552\n",
      "Epoch 978/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3879 - accuracy: 0.8799 - val_loss: 8.4318 - val_accuracy: 0.8552\n",
      "Epoch 979/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3231 - accuracy: 0.8792 - val_loss: 7.9981 - val_accuracy: 0.8582\n",
      "Epoch 980/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3467 - accuracy: 0.8843 - val_loss: 8.3232 - val_accuracy: 0.8479\n",
      "Epoch 981/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.4088 - accuracy: 0.8817 - val_loss: 7.9938 - val_accuracy: 0.8567\n",
      "Epoch 982/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 3.3772 - accuracy: 0.8814 - val_loss: 8.0967 - val_accuracy: 0.8567\n",
      "Epoch 983/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3646 - accuracy: 0.8880 - val_loss: 8.1793 - val_accuracy: 0.8597\n",
      "Epoch 984/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 3.5176 - accuracy: 0.8780 - val_loss: 8.4446 - val_accuracy: 0.8567\n",
      "Epoch 985/998\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 3.3983 - accuracy: 0.8814 - val_loss: 8.7342 - val_accuracy: 0.8508\n",
      "Epoch 986/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.5834 - accuracy: 0.8814 - val_loss: 8.2844 - val_accuracy: 0.8641\n",
      "Epoch 987/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3553 - accuracy: 0.8825 - val_loss: 7.9530 - val_accuracy: 0.8508\n",
      "Epoch 988/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3826 - accuracy: 0.8784 - val_loss: 8.2793 - val_accuracy: 0.8582\n",
      "Epoch 989/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.2856 - accuracy: 0.8836 - val_loss: 8.2080 - val_accuracy: 0.8464\n",
      "Epoch 990/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.5304 - accuracy: 0.8821 - val_loss: 8.0452 - val_accuracy: 0.8508\n",
      "Epoch 991/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.2931 - accuracy: 0.8795 - val_loss: 8.4343 - val_accuracy: 0.8464\n",
      "Epoch 992/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3606 - accuracy: 0.8803 - val_loss: 8.2886 - val_accuracy: 0.8582\n",
      "Epoch 993/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.5478 - accuracy: 0.8865 - val_loss: 8.2938 - val_accuracy: 0.8612\n",
      "Epoch 994/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.2122 - accuracy: 0.8825 - val_loss: 7.7788 - val_accuracy: 0.8582\n",
      "Epoch 995/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3998 - accuracy: 0.8836 - val_loss: 8.2871 - val_accuracy: 0.8567\n",
      "Epoch 996/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.4742 - accuracy: 0.8847 - val_loss: 8.3055 - val_accuracy: 0.8523\n",
      "Epoch 997/998\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 3.3890 - accuracy: 0.8817 - val_loss: 8.4270 - val_accuracy: 0.8567\n",
      "Epoch 998/998\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 3.3191 - accuracy: 0.8825 - val_loss: 8.4908 - val_accuracy: 0.8479\n",
      "Val loss:  8.49083423614502\n",
      "Accuracy:  0.8824833631515503\n"
     ]
    }
   ],
   "source": [
    "l1=4.5927655210613596e-08 \n",
    "l2=6.769705259483123e-10\n",
    "model_5 = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(train_features.shape[1]), name=\"in_layer\"),\n",
    "        layers.Dense(112, activation='tanh', kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2), name=\"dl1\"),\n",
    "        layers.Dense(112, activation='tanh', kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2), name=\"dl2\"),\n",
    "        layers.Dense(112, activation='tanh', kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2), name=\"dl3\"),\n",
    "        layers.Reshape((1,112), name=\"reshape_layer\"),\n",
    "        layers.SimpleRNN(112, activation='tanh', name=\"rnn2_layer\"),\n",
    "        layers.Dense(3, name=\"out_layer\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "lr = 0.0017172015688603477\n",
    "b1 = 0.8539642649814688\n",
    "b2 = 0.9358548594051231\n",
    "cv =  0.964758137195115\n",
    "num_batches=32\n",
    "# opt='sgd'\n",
    "scaler='standard_scaler'\n",
    "loss_func = 'huber_loss'\n",
    "num_epochs=998\n",
    "\n",
    "model_5.summary()\n",
    "opt = Adam(learning_rate=lr, beta_1=b1, beta_2=b2, clipvalue=cv)\n",
    "#opt = SGD(learning_rate=lr) #, clipvalue=cv)\n",
    "model_5.compile(loss=loss_func, optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=30)\n",
    "history_5 = model_5.fit(scaled_train_features, train_labels, validation_split=0.2, verbose=1, epochs=num_epochs, batch_size=num_batches) #, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the final performance of the model on the validation data\n",
    "val_loss = history_5.history['val_loss'][-1]\n",
    "accuracy = history_5.history['accuracy'][-1]\n",
    "print(\"Val loss: \", val_loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Since Open3D 0.15, installing Open3D via conda is deprecated. Please re-install Open3D via: `pip install open3d -U`.\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in specific point cloud that was dropped from dataset\n",
    "file_name_w = \"C:/Users/emily/OneDrive/Desktop/3d_transformation_prediction/2023-07-21__12-59-17-030_sorghum_west_downsampled/west_downsampled/2023-07-21__16-34-56-036/5988af8d-12e4-49b5-b929-14af2e97f158__Top-heading-west.ply\"\n",
    "west_ply_test = o3d.io.read_point_cloud(file_name_w)\n",
    "west_ply_target = o3d.io.read_point_cloud(file_name_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get proper tensor for network prediction\n",
    "target_transformation = test_ply_metadata['data'] # save expected value\n",
    "target_transformation\n",
    "\n",
    "test_ply_metadata.pop('data')\n",
    "test_ply_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "net_results = model_5.predict(test_ply_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix weird pandas series transformation\n",
    "target_transformation= target_transformation.tolist()\n",
    "target_transformation[0]\n",
    "tt=[]\n",
    "for i in target_transformation[0]:\n",
    "    tt.append(i)\n",
    "\n",
    "tt.append(1)\n",
    "target_transformation=tt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix weird pandas series transformation\n",
    "nr=[]\n",
    "for i in net_results[0]:\n",
    "    nr.append(i)\n",
    "\n",
    "nr.append(1)\n",
    "net_results=nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_results = np.array(net_results)\n",
    "target_transformation = np.array(target_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix\n",
    "net_results= np.stack((net_results, [0,1,0,0], [0,0,1,0], [1,0,0,0]))\n",
    "target_transformation= np.stack((target_transformation, [0,1,0,0], [0,0,1,0], [1,0,0,0]))\n",
    "\n",
    "net_results = net_results.T\n",
    "target_transformation =target_transformation.T\n",
    "\n",
    "net_results[:, [3,0]] = net_results[:, [0,3]]\n",
    "target_transformation[:, [3,0]] = target_transformation[:, [0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 393763 points."
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply transformations\n",
    "west_ply_test.transform(net_results)\n",
    "west_ply_target.transform(target_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(\"target_results.ply\", west_ply_target, write_ascii=False)\n",
    "o3d.io.write_point_cloud(\"net_results.ply\", west_ply_test, write_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "#     # the method Vector3dVector() will convert numpy array of shape (n, 3) to Open3D format.\n",
    "#     # see http://www.open3d.org/docs/release/python_api/open3d.utility.Vector3dVector.html#open3d.utility.Vector3dVector\n",
    "# pcd.points = o3d.utility.Vector3dVector(net_results)\n",
    "\n",
    "#     # http://www.open3d.org/docs/release/python_api/open3d.io.write_point_cloud.html#open3d.io.write_point_cloud\n",
    "# o3d.io.write_point_cloud(\"net_results.ply\", pcd, write_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1.history['loss'][:num_epochs], label='loss-4 layers')\n",
    "plt.plot(history_2.history['loss'][:num_epochs], label='loss-5 layers')\n",
    "plt.plot(history_3.history['loss'][:num_epochs], label='loss-6 layers')\n",
    "\n",
    "\n",
    "# plt.ylim([0, 10])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [mm]')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('comp_layers_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('comp_layers_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0][0]\n",
    "test_predictions = model_5.predict(test_features)\n",
    "test_predictions[0][1]\n",
    "test_labels[0]\n",
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model_5.predict(test_features)#.flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "fig = plt.plot(lims, lims)\n",
    "\n",
    "plt.savefig('test_predictions_original.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
